{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c62ec8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:18.739284Z",
     "iopub.status.busy": "2025-11-14T15:39:18.738689Z",
     "iopub.status.idle": "2025-11-14T15:39:29.305541Z",
     "shell.execute_reply": "2025-11-14T15:39:29.304594Z"
    },
    "papermill": {
     "duration": 10.572974,
     "end_time": "2025-11-14T15:39:29.306969",
     "exception": false,
     "start_time": "2025-11-14T15:39:18.733995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eee-g513/train.csv\n",
      "/kaggle/input/eee-g513/test.csv\n",
      "/kaggle/input/eee-g513/cost_of_living.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:10]:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfa2289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:29.313903Z",
     "iopub.status.busy": "2025-11-14T15:39:29.313327Z",
     "iopub.status.idle": "2025-11-14T15:39:29.395389Z",
     "shell.execute_reply": "2025-11-14T15:39:29.394365Z"
    },
    "papermill": {
     "duration": 0.087147,
     "end_time": "2025-11-14T15:39:29.396931",
     "exception": false,
     "start_time": "2025-11-14T15:39:29.309784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6525, 6), Test: (2790, 5), COL: (1528, 56)\n",
      "\n",
      "Target stats:\n",
      "count      6480.000000\n",
      "mean      53169.866584\n",
      "std       27592.877914\n",
      "min        3836.556547\n",
      "25%       28697.390996\n",
      "50%       54673.064063\n",
      "75%       72742.000000\n",
      "max      157747.634644\n",
      "Name: salary_average, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data\n",
    "DATA_PATH = \"/kaggle/input/eee-g513\"\n",
    "\n",
    "train_raw = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "test_raw = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
    "colv = pd.read_csv(f\"{DATA_PATH}/cost_of_living.csv\")\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}, COL: {colv.shape}\")\n",
    "print(f\"\\nTarget stats:\\n{train_raw['salary_average'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0ede00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:29.403664Z",
     "iopub.status.busy": "2025-11-14T15:39:29.403359Z",
     "iopub.status.idle": "2025-11-14T15:39:29.450936Z",
     "shell.execute_reply": "2025-11-14T15:39:29.449995Z"
    },
    "papermill": {
     "duration": 0.052639,
     "end_time": "2025-11-14T15:39:29.452276",
     "exception": false,
     "start_time": "2025-11-14T15:39:29.399637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge - Train: (6525, 59), Test: (2790, 58)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Simple COL Merge - Just median per city\n",
    "keys = ['city_id'] if 'city_id' in train_raw.columns else ['country', 'state', 'city']\n",
    "\n",
    "# Aggregate COL with median\n",
    "colv_agg = colv.groupby(keys, as_index=False).median(numeric_only=True)\n",
    "\n",
    "train = train_raw.merge(colv_agg, on=keys, how='left', suffixes=('', '_drop'))\n",
    "test = test_raw.merge(colv_agg, on=keys, how='left', suffixes=('', '_drop'))\n",
    "\n",
    "train = train[[c for c in train.columns if not c.endswith('_drop')]]\n",
    "test = test[[c for c in test.columns if not c.endswith('_drop')]]\n",
    "\n",
    "print(f\"After merge - Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ba1348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:29.458923Z",
     "iopub.status.busy": "2025-11-14T15:39:29.458612Z",
     "iopub.status.idle": "2025-11-14T15:39:29.477428Z",
     "shell.execute_reply": "2025-11-14T15:39:29.476565Z"
    },
    "papermill": {
     "duration": 0.0237,
     "end_time": "2025-11-14T15:39:29.478766",
     "exception": false,
     "start_time": "2025-11-14T15:39:29.455066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 45 invalid targets\n",
      "Features: 58\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Target Cleaning\n",
    "TARGET = \"salary_average\"\n",
    "\n",
    "before = len(train)\n",
    "train = train[train[TARGET].notna() & (train[TARGET] > 0)].reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(train)} invalid targets\")\n",
    "\n",
    "feat_cols = [c for c in train.columns if c in test.columns and c != TARGET]\n",
    "print(f\"Features: {len(feat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f338530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:29.485832Z",
     "iopub.status.busy": "2025-11-14T15:39:29.485205Z",
     "iopub.status.idle": "2025-11-14T15:39:29.792518Z",
     "shell.execute_reply": "2025-11-14T15:39:29.791548Z"
    },
    "papermill": {
     "duration": 0.312619,
     "end_time": "2025-11-14T15:39:29.794102",
     "exception": false,
     "start_time": "2025-11-14T15:39:29.481483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after engineering: 79\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Global Feature Engineering (computed once on full train)\n",
    "def create_global_features(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Create features using FULL train data (computed once).\n",
    "    This matches your simpler approach that scored 0.24.\n",
    "    \"\"\"\n",
    "    # Compute encodings on FULL train\n",
    "    encodings = {}\n",
    "    \n",
    "    # Country-role\n",
    "    encodings['country_role'] = train_df.groupby(['country', 'role'])['salary_average'].agg(['mean', 'median', 'std']).to_dict()\n",
    "    \n",
    "    # Country\n",
    "    encodings['country'] = train_df.groupby('country')['salary_average'].agg(['mean', 'median', 'std', 'count']).to_dict()\n",
    "    \n",
    "    # State\n",
    "    encodings['state'] = train_df.groupby('state')['salary_average'].agg(['mean', 'median', 'count']).to_dict()\n",
    "    \n",
    "    # Role\n",
    "    encodings['role'] = train_df.groupby('role')['salary_average'].agg(['mean', 'median', 'std', 'min', 'max']).to_dict()\n",
    "    \n",
    "    # Global fallbacks\n",
    "    global_mean = train_df['salary_average'].mean()\n",
    "    global_median = train_df['salary_average'].median()\n",
    "    global_std = train_df['salary_average'].std()\n",
    "    \n",
    "    # Apply to both train and test\n",
    "    for df in [train_df, test_df]:\n",
    "        # Country-role\n",
    "        df['te_country_role_mean'] = df.apply(\n",
    "            lambda x: encodings['country_role']['mean'].get((x['country'], x['role']), global_mean), axis=1)\n",
    "        df['te_country_role_median'] = df.apply(\n",
    "            lambda x: encodings['country_role']['median'].get((x['country'], x['role']), global_median), axis=1)\n",
    "        \n",
    "        # Country\n",
    "        df['te_country_mean'] = df['country'].map(encodings['country']['mean']).fillna(global_mean)\n",
    "        df['te_country_median'] = df['country'].map(encodings['country']['median']).fillna(global_median)\n",
    "        df['te_country_std'] = df['country'].map(encodings['country']['std']).fillna(global_std)\n",
    "        \n",
    "        # State\n",
    "        df['te_state_mean'] = df['state'].map(encodings['state']['mean']).fillna(df['te_country_mean'])\n",
    "        df['te_state_median'] = df['state'].map(encodings['state']['median']).fillna(df['te_country_median'])\n",
    "        \n",
    "        # Role\n",
    "        df['te_role_mean'] = df['role'].map(encodings['role']['mean']).fillna(global_mean)\n",
    "        df['te_role_median'] = df['role'].map(encodings['role']['median']).fillna(global_median)\n",
    "        df['te_role_std'] = df['role'].map(encodings['role']['std']).fillna(global_std)\n",
    "        df['te_role_range'] = df['role'].map(encodings['role']['max']).fillna(global_mean) - \\\n",
    "                              df['role'].map(encodings['role']['min']).fillna(global_mean)\n",
    "        \n",
    "        # COL interactions\n",
    "        col_cols = [c for c in df.columns if 'col_' in c.lower() or 'rent' in c.lower() or 'grocer' in c.lower()]\n",
    "        if len(col_cols) > 0:\n",
    "            for col in col_cols:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "            \n",
    "            df['col_mean'] = df[col_cols].mean(axis=1)\n",
    "            df['col_median'] = df[col_cols].median(axis=1)\n",
    "            df['col_std'] = df[col_cols].std(axis=1).fillna(0)\n",
    "            \n",
    "            # Adjusted features\n",
    "            df['te_role_per_col'] = df['te_role_mean'] / (df['col_mean'] + 1)\n",
    "            df['te_country_per_col'] = df['te_country_mean'] / (df['col_mean'] + 1)\n",
    "            df['te_role_x_col'] = df['te_role_mean'] * df['col_mean']\n",
    "        \n",
    "        # Ratios\n",
    "        df['country_vs_role'] = df['te_country_mean'] / (df['te_role_mean'] + 1)\n",
    "        df['state_vs_country'] = df['te_state_mean'] / (df['te_country_mean'] + 1)\n",
    "        \n",
    "        # Log transforms\n",
    "        df['log_te_role_mean'] = np.log1p(df['te_role_mean'])\n",
    "        df['log_te_country_mean'] = np.log1p(df['te_country_mean'])\n",
    "        \n",
    "    return train_df, test_df\n",
    "\n",
    "train, test = create_global_features(train, test)\n",
    "feat_cols = [c for c in train.columns if c in test.columns and c != TARGET]\n",
    "print(f\"Features after engineering: {len(feat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d7dc52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:29.801569Z",
     "iopub.status.busy": "2025-11-14T15:39:29.800888Z",
     "iopub.status.idle": "2025-11-14T15:39:30.021180Z",
     "shell.execute_reply": "2025-11-14T15:39:30.020059Z"
    },
    "papermill": {
     "duration": 0.225663,
     "end_time": "2025-11-14T15:39:30.022644",
     "exception": false,
     "start_time": "2025-11-14T15:39:29.796981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: 75, Categorical: 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Minimal Preprocessing\n",
    "num_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "print(f\"Numeric: {len(num_cols)}, Categorical: {len(cat_cols)}\")\n",
    "\n",
    "# Only clip extreme outliers (0.5% and 99.5%)\n",
    "for c in num_cols:\n",
    "    q_low, q_high = train[c].quantile([0.005, 0.995])\n",
    "    train[c] = train[c].clip(q_low, q_high)\n",
    "    test[c] = test[c].clip(q_low, q_high)\n",
    "\n",
    "# Impute with median\n",
    "for c in num_cols:\n",
    "    med = train[c].median()\n",
    "    train[c] = train[c].fillna(med)\n",
    "    test[c] = test[c].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9752196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:30.029662Z",
     "iopub.status.busy": "2025-11-14T15:39:30.029129Z",
     "iopub.status.idle": "2025-11-14T15:39:30.035664Z",
     "shell.execute_reply": "2025-11-14T15:39:30.034859Z"
    },
    "papermill": {
     "duration": 0.011403,
     "end_time": "2025-11-14T15:39:30.036960",
     "exception": false,
     "start_time": "2025-11-14T15:39:30.025557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Strategy: GroupKFold on 'city_id' with 5 folds\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: CV Setup\n",
    "group_key = 'city_id' if 'city_id' in train.columns else 'city'\n",
    "groups = train[group_key] if group_key in train.columns else train['country']\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "def rmspe(y_true, y_pred, eps=1e-6):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = (y_true > eps) & np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if mask.sum() == 0:\n",
    "        return np.inf\n",
    "    return np.sqrt(np.mean(((y_true[mask] - y_pred[mask]) / y_true[mask]) ** 2))\n",
    "\n",
    "print(f\"CV Strategy: GroupKFold on '{group_key}' with {gkf.get_n_splits()} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884bafc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:30.044120Z",
     "iopub.status.busy": "2025-11-14T15:39:30.043796Z",
     "iopub.status.idle": "2025-11-14T15:39:58.232391Z",
     "shell.execute_reply": "2025-11-14T15:39:58.231799Z"
    },
    "papermill": {
     "duration": 28.194111,
     "end_time": "2025-11-14T15:39:58.233939",
     "exception": false,
     "start_time": "2025-11-14T15:39:30.039828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM Training ===\n",
      "Fold 1: RMSPE = 0.0556 | Iterations = 771\n",
      "Fold 2: RMSPE = 0.0354 | Iterations = 910\n",
      "Fold 3: RMSPE = 0.0459 | Iterations = 693\n",
      "Fold 4: RMSPE = 0.0449 | Iterations = 936\n",
      "Fold 5: RMSPE = 0.0452 | Iterations = 1997\n",
      "\n",
      "LGBM OOF RMSPE: 0.0471\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: LightGBM - Focus on single best model\n",
    "lgb_oof = np.zeros(len(train))\n",
    "lgb_test = np.zeros(len(test))\n",
    "y_oof_true = np.zeros(len(train))\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'rmse',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 63,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.5,\n",
    "    'max_depth': 10,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"\\n=== LightGBM Training ===\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols]\n",
    "    y_tr = train.iloc[tr_idx][TARGET].values\n",
    "    X_va = train.iloc[va_idx][feat_cols]\n",
    "    y_va = train.iloc[va_idx][TARGET].values\n",
    "    \n",
    "    cat_features = [c for c in feat_cols if not pd.api.types.is_numeric_dtype(train[c])]\n",
    "    for c in cat_features:\n",
    "        X_tr[c] = X_tr[c].astype('category')\n",
    "        X_va[c] = X_va[c].astype('category')\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_tr, label=np.log1p(y_tr), categorical_feature=cat_features)\n",
    "    dvalid = lgb.Dataset(X_va, label=np.log1p(y_va), categorical_feature=cat_features)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        dtrain,\n",
    "        valid_sets=[dvalid],\n",
    "        num_boost_round=2000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=200, verbose=False),\n",
    "            lgb.log_evaluation(period=0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X_te = test[feat_cols].copy()\n",
    "    for c in cat_features:\n",
    "        X_te[c] = X_te[c].astype('category')\n",
    "    \n",
    "    va_pred = np.expm1(model.predict(X_va, num_iteration=model.best_iteration))\n",
    "    te_pred = np.expm1(model.predict(X_te, num_iteration=model.best_iteration))\n",
    "    \n",
    "    lgb_oof[va_idx] = va_pred\n",
    "    lgb_test += te_pred / gkf.n_splits\n",
    "    y_oof_true[va_idx] = y_va\n",
    "    \n",
    "    fold_score = rmspe(y_va, va_pred)\n",
    "    print(f\"Fold {fold}: RMSPE = {fold_score:.4f} | Iterations = {model.best_iteration}\")\n",
    "\n",
    "lgb_cv_score = rmspe(y_oof_true, lgb_oof)\n",
    "print(f\"\\nLGBM OOF RMSPE: {lgb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ff14ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:58.241301Z",
     "iopub.status.busy": "2025-11-14T15:39:58.241018Z",
     "iopub.status.idle": "2025-11-14T15:39:58.264907Z",
     "shell.execute_reply": "2025-11-14T15:39:58.263913Z"
    },
    "papermill": {
     "duration": 0.029268,
     "end_time": "2025-11-14T15:39:58.266302",
     "exception": false,
     "start_time": "2025-11-14T15:39:58.237034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission Validation:\n",
      "  Shape: (2790, 2)\n",
      "  Expected: (2790, 2)\n",
      "  Min: $4,944.92\n",
      "  Max: $124,139.83\n",
      "  Mean: $55,137.47\n",
      "\n",
      "✓ Submission saved!\n",
      "   ID  salary_average\n",
      "0   1    80168.761167\n",
      "1   2    84155.107174\n",
      "2   3    86535.116387\n",
      "3   4    65220.089803\n",
      "4   5    54671.250753\n",
      "5   6    67741.196871\n",
      "6   7    54706.187518\n",
      "7   8    66385.627188\n",
      "8   9    85561.458516\n",
      "9  10    87102.786358\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Create Submission\n",
    "id_col = 'ID' if 'ID' in test_raw.columns else 'id'\n",
    "test_ids = test_raw[id_col].values if id_col in test_raw.columns else np.arange(1, len(test_raw) + 1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'salary_average': lgb_test\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission Validation:\")\n",
    "print(f\"  Shape: {submission.shape}\")\n",
    "print(f\"  Expected: ({len(test_raw)}, 2)\")\n",
    "print(f\"  Min: ${submission['salary_average'].min():,.2f}\")\n",
    "print(f\"  Max: ${submission['salary_average'].max():,.2f}\")\n",
    "print(f\"  Mean: ${submission['salary_average'].mean():,.2f}\")\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\n✓ Submission saved!\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6144d208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T15:39:58.273633Z",
     "iopub.status.busy": "2025-11-14T15:39:58.273379Z",
     "iopub.status.idle": "2025-11-14T15:39:58.403431Z",
     "shell.execute_reply": "2025-11-14T15:39:58.402558Z"
    },
    "papermill": {
     "duration": 0.135363,
     "end_time": "2025-11-14T15:39:58.404757",
     "exception": false,
     "start_time": "2025-11-14T15:39:58.269394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Pipeline complete!\n",
      "OOF RMSPE: 0.0471\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Cleanup\n",
    "gc.collect()\n",
    "print(\"\\n✓ Pipeline complete!\")\n",
    "print(f\"OOF RMSPE: {lgb_cv_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14422847,
     "sourceId": 116641,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 45.739006,
   "end_time": "2025-11-14T15:39:59.329504",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T15:39:13.590498",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
