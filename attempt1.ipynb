{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965cf342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:39.887638Z",
     "iopub.status.busy": "2025-11-08T14:29:39.887331Z",
     "iopub.status.idle": "2025-11-08T14:29:41.762056Z",
     "shell.execute_reply": "2025-11-08T14:29:41.761126Z"
    },
    "papermill": {
     "duration": 1.881143,
     "end_time": "2025-11-08T14:29:41.763547",
     "exception": false,
     "start_time": "2025-11-08T14:29:39.882404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eee-g513/train.csv\n",
      "/kaggle/input/eee-g513/test.csv\n",
      "/kaggle/input/eee-g513/cost_of_living.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports & file listing\n",
    "import os, gc, warnings, numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:20]:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed0ada1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:41.772081Z",
     "iopub.status.busy": "2025-11-08T14:29:41.771267Z",
     "iopub.status.idle": "2025-11-08T14:29:41.893001Z",
     "shell.execute_reply": "2025-11-08T14:29:41.892303Z"
    },
    "papermill": {
     "duration": 0.127652,
     "end_time": "2025-11-08T14:29:41.894326",
     "exception": false,
     "start_time": "2025-11-08T14:29:41.766674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6525, 6) (2799, 5) (1528, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>role</th>\n",
       "      <th>salary_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Thornton</td>\n",
       "      <td>accountant</td>\n",
       "      <td>95110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>United States Of America</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Thornton</td>\n",
       "      <td>automation-analyst</td>\n",
       "      <td>104766.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                   country     state      city                role  \\\n",
       "0   1  United States Of America  Colorado  Thornton          accountant   \n",
       "1   2  United States Of America  Colorado  Thornton  automation-analyst   \n",
       "\n",
       "   salary_average  \n",
       "0         95110.0  \n",
       "1        104766.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load data\n",
    "BASE = '/kaggle/input/eee-g513'\n",
    "cands = []\n",
    "for p, _, f in os.walk(BASE):\n",
    "    fset = {x.lower() for x in f}\n",
    "    if {'train.csv','test.csv'}.issubset(fset):\n",
    "        cands.append(p)\n",
    "DATA_PATH = cands[0] if cands else BASE\n",
    "\n",
    "train = pd.read_csv(f'{DATA_PATH}/train.csv')\n",
    "test  = pd.read_csv(f'{DATA_PATH}/test.csv')\n",
    "\n",
    "# Optional COL\n",
    "colv_path = os.path.join(DATA_PATH, 'cost_of_living.csv')\n",
    "colv = pd.read_csv(colv_path) if os.path.exists(colv_path) else None\n",
    "\n",
    "print(train.shape, test.shape, None if colv is None else colv.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3af0249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:41.902285Z",
     "iopub.status.busy": "2025-11-08T14:29:41.901460Z",
     "iopub.status.idle": "2025-11-08T14:29:41.953741Z",
     "shell.execute_reply": "2025-11-08T14:29:41.952991Z"
    },
    "papermill": {
     "duration": 0.057865,
     "end_time": "2025-11-08T14:29:41.955269",
     "exception": false,
     "start_time": "2025-11-08T14:29:41.897404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3) Merge cost_of_living if available\n",
    "if colv is not None:\n",
    "    if 'city_id' in train.columns and 'city_id' in colv.columns:\n",
    "        keys = ['city_id']\n",
    "    else:\n",
    "        keys = ['city','country']\n",
    "    colv_uniq = colv.drop_duplicates(subset=keys).copy()\n",
    "    train = train.merge(colv_uniq, on=keys, how='left', suffixes=('','_col'))\n",
    "    test  = test.merge(colv_uniq,  on=keys, how='left', suffixes=('','_col'))\n",
    "\n",
    "# Drop duplicate-named columns created by merges\n",
    "if train.columns.duplicated().any():\n",
    "    train = train.loc[:, ~train.columns.duplicated()]\n",
    "if test.columns.duplicated().any():\n",
    "    test = test.loc[:, ~test.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39bcdcf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:41.963092Z",
     "iopub.status.busy": "2025-11-08T14:29:41.962763Z",
     "iopub.status.idle": "2025-11-08T14:29:41.990003Z",
     "shell.execute_reply": "2025-11-08T14:29:41.988955Z"
    },
    "papermill": {
     "duration": 0.033244,
     "end_time": "2025-11-08T14:29:41.991597",
     "exception": false,
     "start_time": "2025-11-08T14:29:41.958353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 45 rows with invalid targets.\n"
     ]
    }
   ],
   "source": [
    "# 4) Target & ID\n",
    "target = 'salary_average'\n",
    "\n",
    "# Detect/standardize ID for submission\n",
    "possible_ids = ['ID','id','Id','row_id','RowId','rowID']\n",
    "id_col = next((c for c in possible_ids if c in test.columns), None)\n",
    "if id_col is None:\n",
    "    # create an ID column from index to be safe\n",
    "    test = test.reset_index(drop=False).rename(columns={'index':'ID'})\n",
    "    id_col = 'ID'\n",
    "else:\n",
    "    # ensure it's named 'ID' in submission later\n",
    "    pass\n",
    "\n",
    "# Drop invalid targets; then align columns\n",
    "before = len(train)\n",
    "train = train[train[target].notna() & (train[target] > 0)].reset_index(drop=True)\n",
    "print(f'Dropped {before - len(train)} rows with invalid targets.')\n",
    "\n",
    "# Keep common features between train/test (exclude target and the detected id_col if present in train)\n",
    "exclude = {target}\n",
    "if id_col in train.columns:\n",
    "    exclude.add(id_col)\n",
    "common_feats = [c for c in train.columns if c in test.columns and c not in exclude]\n",
    "\n",
    "train = pd.concat([train[common_feats], train[[target]]], axis=1)\n",
    "test  = test[common_feats].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46976e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:41.999588Z",
     "iopub.status.busy": "2025-11-08T14:29:41.998680Z",
     "iopub.status.idle": "2025-11-08T14:29:42.229222Z",
     "shell.execute_reply": "2025-11-08T14:29:42.228353Z"
    },
    "papermill": {
     "duration": 0.236034,
     "end_time": "2025-11-08T14:29:42.230707",
     "exception": false,
     "start_time": "2025-11-08T14:29:41.994673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformed numeric features: 0\n"
     ]
    }
   ],
   "source": [
    "# 5) Dtypes & numeric cleanup\n",
    "feat_cols = common_feats[:]\n",
    "\n",
    "# Convert numeric-like objects to numeric\n",
    "for c in feat_cols:\n",
    "    if train[c].dtype == 'object':\n",
    "        tr_num = pd.to_numeric(train[c], errors='coerce')\n",
    "        te_num = pd.to_numeric(test[c],  errors='coerce')\n",
    "        if tr_num.notna().mean() > 0.95 and te_num.notna().mean() > 0.95:\n",
    "            train[c] = tr_num\n",
    "            test[c]  = te_num\n",
    "\n",
    "num_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "# Winsorize (clip 1/99%) to reduce outlier impact\n",
    "for c in num_cols:\n",
    "    q1, q99 = train[c].quantile([0.01, 0.99])\n",
    "    train[c] = train[c].clip(q1, q99)\n",
    "    test[c]  = test[c].clip(q1, q99)\n",
    "\n",
    "# Log-transform skewed positive numeric features\n",
    "skewed = []\n",
    "for c in num_cols:\n",
    "    if (train[c] > 0).all():\n",
    "        if train[c].skew() > 1.0:\n",
    "            train[c] = np.log1p(train[c])\n",
    "            test[c]  = np.log1p(test[c])\n",
    "            skewed.append(c)\n",
    "print('Log-transformed numeric features:', len(skewed))\n",
    "\n",
    "# Impute numeric with train median\n",
    "for c in num_cols:\n",
    "    med = train[c].median()\n",
    "    train[c] = train[c].fillna(med)\n",
    "    test[c]  = test[c].fillna(med)\n",
    "\n",
    "# Categorical casting (for LGBM); CatBoost will use strings later\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].astype('category')\n",
    "    test[c]  = test[c].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b882f820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:42.238647Z",
     "iopub.status.busy": "2025-11-08T14:29:42.237829Z",
     "iopub.status.idle": "2025-11-08T14:29:43.760674Z",
     "shell.execute_reply": "2025-11-08T14:29:43.759585Z"
    },
    "papermill": {
     "duration": 1.528423,
     "end_time": "2025-11-08T14:29:43.762274",
     "exception": false,
     "start_time": "2025-11-08T14:29:42.233851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6) GroupKFold by city_id (or city), fallback to country\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_key = 'city_id' if 'city_id' in train.columns else ('city' if 'city' in train.columns else ('country' if 'country' in train.columns else None))\n",
    "groups = train[group_key] if group_key is not None else pd.Series(['all']*len(train))\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "def rmspe(y_true, y_pred, eps=1e-6):\n",
    "    y_true = np.asarray(y_true, float); y_pred = np.asarray(y_pred, float)\n",
    "    mask = (y_true > eps) & np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return float(np.sqrt(np.mean(((y_true[mask]-y_pred[mask])/y_true[mask])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71c591d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:43.769879Z",
     "iopub.status.busy": "2025-11-08T14:29:43.769443Z",
     "iopub.status.idle": "2025-11-08T14:29:43.779112Z",
     "shell.execute_reply": "2025-11-08T14:29:43.778373Z"
    },
    "papermill": {
     "duration": 0.015254,
     "end_time": "2025-11-08T14:29:43.780616",
     "exception": false,
     "start_time": "2025-11-08T14:29:43.765362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7) Target encodings without leakage\n",
    "TE_COLS = ['te_country','te_role','te_country_role']\n",
    "\n",
    "def add_te(X_tr, y_tr, X_tgt):\n",
    "    Xt = X_tgt.copy()\n",
    "    gmean = float(y_tr.mean())\n",
    "\n",
    "    if 'country' in X_tr.columns and 'country' in Xt.columns:\n",
    "        df = pd.DataFrame({'key': X_tr['country'].astype(str), 'y': y_tr.values})\n",
    "        m = df.groupby('key')['y'].mean()\n",
    "        Xt['te_country'] = Xt['country'].astype(str).map(m).astype('float64').fillna(gmean)\n",
    "\n",
    "    if 'role' in X_tr.columns and 'role' in Xt.columns:\n",
    "        df = pd.DataFrame({'key': X_tr['role'].astype(str), 'y': y_tr.values})\n",
    "        m = df.groupby('key')['y'].mean()\n",
    "        Xt['te_role'] = Xt['role'].astype(str).map(m).astype('float64').fillna(gmean)\n",
    "\n",
    "    if {'country','role'}.issubset(X_tr.columns) and {'country','role'}.issubset(Xt.columns):\n",
    "        df = pd.DataFrame({'country': X_tr['country'].astype(str), 'role': X_tr['role'].astype(str), 'y': y_tr.values})\n",
    "        m = df.groupby(['country','role'])['y'].mean().to_dict()\n",
    "        cr_keys = list(zip(Xt['country'].astype(str), Xt['role'].astype(str)))\n",
    "        Xt['te_country_role'] = pd.Series([m.get(k, np.nan) for k in cr_keys], index=Xt.index).astype('float64').fillna(gmean)\n",
    "\n",
    "    return Xt\n",
    "\n",
    "y_true_oof = np.zeros(len(train))  # ground truth aligned to OOF slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b88ead3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:29:43.788683Z",
     "iopub.status.busy": "2025-11-08T14:29:43.787667Z",
     "iopub.status.idle": "2025-11-08T14:30:01.056254Z",
     "shell.execute_reply": "2025-11-08T14:30:01.055537Z"
    },
    "papermill": {
     "duration": 17.274531,
     "end_time": "2025-11-08T14:30:01.058229",
     "exception": false,
     "start_time": "2025-11-08T14:29:43.783698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 0.0469595\tvalid_1's rmse: 0.0864487\n",
      "[400]\ttraining's rmse: 0.0338952\tvalid_1's rmse: 0.0877699\n",
      "[LGBM] Fold 1 RMSPE: 0.0807\n",
      "[200]\ttraining's rmse: 0.0517905\tvalid_1's rmse: 0.109654\n",
      "[400]\ttraining's rmse: 0.0433411\tvalid_1's rmse: 0.107644\n",
      "[600]\ttraining's rmse: 0.0404475\tvalid_1's rmse: 0.106634\n",
      "[800]\ttraining's rmse: 0.0389424\tvalid_1's rmse: 0.105973\n",
      "[1000]\ttraining's rmse: 0.0380045\tvalid_1's rmse: 0.105511\n",
      "[1200]\ttraining's rmse: 0.0373178\tvalid_1's rmse: 0.105194\n",
      "[1400]\ttraining's rmse: 0.0368229\tvalid_1's rmse: 0.104947\n",
      "[1600]\ttraining's rmse: 0.0364291\tvalid_1's rmse: 0.104765\n",
      "[1800]\ttraining's rmse: 0.0360908\tvalid_1's rmse: 0.104655\n",
      "[2000]\ttraining's rmse: 0.0358222\tvalid_1's rmse: 0.104572\n",
      "[2200]\ttraining's rmse: 0.0355958\tvalid_1's rmse: 0.104498\n",
      "[2400]\ttraining's rmse: 0.0354025\tvalid_1's rmse: 0.104416\n",
      "[2600]\ttraining's rmse: 0.0352206\tvalid_1's rmse: 0.104387\n",
      "[2800]\ttraining's rmse: 0.0350581\tvalid_1's rmse: 0.104318\n",
      "[3000]\ttraining's rmse: 0.0349232\tvalid_1's rmse: 0.104349\n",
      "[3200]\ttraining's rmse: 0.0347762\tvalid_1's rmse: 0.104254\n",
      "[3400]\ttraining's rmse: 0.0346599\tvalid_1's rmse: 0.104268\n",
      "[LGBM] Fold 2 RMSPE: 0.1211\n",
      "[200]\ttraining's rmse: 0.0531801\tvalid_1's rmse: 0.311964\n",
      "[400]\ttraining's rmse: 0.0438918\tvalid_1's rmse: 0.30843\n",
      "[600]\ttraining's rmse: 0.0408554\tvalid_1's rmse: 0.307845\n",
      "[800]\ttraining's rmse: 0.0392309\tvalid_1's rmse: 0.307621\n",
      "[1000]\ttraining's rmse: 0.0382301\tvalid_1's rmse: 0.307422\n",
      "[1200]\ttraining's rmse: 0.0374768\tvalid_1's rmse: 0.307416\n",
      "[1400]\ttraining's rmse: 0.0369304\tvalid_1's rmse: 0.307428\n",
      "[LGBM] Fold 3 RMSPE: 0.9275\n",
      "[200]\ttraining's rmse: 0.0523465\tvalid_1's rmse: 0.230266\n",
      "[400]\ttraining's rmse: 0.04367\tvalid_1's rmse: 0.231007\n",
      "[LGBM] Fold 4 RMSPE: 0.4522\n",
      "[200]\ttraining's rmse: 0.0510889\tvalid_1's rmse: 0.178902\n",
      "[400]\ttraining's rmse: 0.0425694\tvalid_1's rmse: 0.178132\n",
      "[600]\ttraining's rmse: 0.0398367\tvalid_1's rmse: 0.178118\n",
      "[LGBM] Fold 5 RMSPE: 0.2818\n",
      "[LGBM] OOF RMSPE: 0.4573\n"
     ]
    }
   ],
   "source": [
    "# 8) LightGBM (log-target)\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_oof = np.zeros(len(train))\n",
    "lgb_test = np.zeros(len(test))\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'rmse',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.035,\n",
    "    'num_leaves': 31,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 1.0,\n",
    "    'lambda_l2': 3.0,\n",
    "    'max_depth': -1,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy().drop(columns=TE_COLS, errors='ignore')\n",
    "    y_tr = train.iloc[tr_idx][target].copy()\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy().drop(columns=TE_COLS, errors='ignore')\n",
    "    y_va = train.iloc[va_idx][target].copy()\n",
    "\n",
    "    # add TEs from training split only\n",
    "    X_tr = add_te(X_tr, y_tr, X_tr)\n",
    "    X_va = add_te(train.iloc[tr_idx][feat_cols], y_tr, X_va)\n",
    "    X_te = add_te(train.iloc[tr_idx][feat_cols], y_tr, test[feat_cols].copy())\n",
    "\n",
    "    cat_in_use = [c for c in X_tr.columns if not pd.api.types.is_numeric_dtype(X_tr[c])]\n",
    "    dtr = lgb.Dataset(X_tr, label=np.log1p(y_tr), categorical_feature=cat_in_use, free_raw_data=True)\n",
    "    dva = lgb.Dataset(X_va, label=np.log1p(y_va), categorical_feature=cat_in_use, free_raw_data=True)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=dtr,\n",
    "        valid_sets=[dtr, dva],\n",
    "        num_boost_round=5000,\n",
    "        callbacks=[lgb.early_stopping(300, verbose=False), lgb.log_evaluation(200)]\n",
    "    )\n",
    "\n",
    "    va_pred = np.expm1(model.predict(X_va, num_iteration=model.best_iteration))\n",
    "    lgb_oof[va_idx] = va_pred\n",
    "    print(f'[LGBM] Fold {fold} RMSPE:', round(rmspe(y_va, va_pred), 4))\n",
    "\n",
    "    lgb_test += np.expm1(model.predict(X_te, num_iteration=model.best_iteration)) / gkf.get_n_splits()\n",
    "\n",
    "print('[LGBM] OOF RMSPE:', round(rmspe(train[target], lgb_oof), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6132f24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:30:01.072115Z",
     "iopub.status.busy": "2025-11-08T14:30:01.070995Z",
     "iopub.status.idle": "2025-11-08T14:32:57.826410Z",
     "shell.execute_reply": "2025-11-08T14:32:57.825334Z"
    },
    "papermill": {
     "duration": 176.763826,
     "end_time": "2025-11-08T14:32:57.827893",
     "exception": false,
     "start_time": "2025-11-08T14:30:01.064067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 1 RMSPE: 0.0856\n",
      "[CatBoost] Fold 2 RMSPE: 0.1202\n",
      "[CatBoost] Fold 3 RMSPE: 0.8926\n",
      "[CatBoost] Fold 4 RMSPE: 0.4278\n",
      "[CatBoost] Fold 5 RMSPE: 0.2546\n",
      "[CatBoost] OOF RMSPE: 0.4376\n"
     ]
    }
   ],
   "source": [
    "# 9) CatBoost (log-target)\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "cb_oof = np.zeros(len(train))\n",
    "cb_test = np.zeros(len(test))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy().drop(columns=TE_COLS, errors='ignore')\n",
    "    y_tr = train.iloc[tr_idx][target].copy()\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy().drop(columns=TE_COLS, errors='ignore')\n",
    "    y_va = train.iloc[va_idx][target].copy()\n",
    "\n",
    "    # add TEs from training split only\n",
    "    X_tr = add_te(X_tr, y_tr, X_tr)\n",
    "    X_va = add_te(train.iloc[tr_idx][feat_cols], y_tr, X_va)\n",
    "    X_te = add_te(train.iloc[tr_idx][feat_cols], y_tr, test[feat_cols].copy())\n",
    "\n",
    "    # Ensure non-numerics are strings with no NaNs\n",
    "    for df in (X_tr, X_va, X_te):\n",
    "        for c in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[c]):\n",
    "                df[c] = df[c].astype('object').where(df[c].notna(), 'Unknown').astype(str)\n",
    "\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in X_tr.columns if not pd.api.types.is_numeric_dtype(X_tr[c])]\n",
    "\n",
    "    tr_pool = Pool(X_tr, np.log1p(y_tr), cat_features=cat_idx)\n",
    "    va_pool = Pool(X_va, np.log1p(y_va), cat_features=cat_idx)\n",
    "    te_pool = Pool(X_te, cat_features=cat_idx)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        learning_rate=0.04,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=6.0,\n",
    "        iterations=10000,\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=400,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "\n",
    "    va_pred = np.expm1(model.predict(va_pool))\n",
    "    cb_oof[va_idx] = va_pred\n",
    "    print(f'[CatBoost] Fold {fold} RMSPE:', round(rmspe(y_va, va_pred), 4))\n",
    "\n",
    "    cb_test += np.expm1(model.predict(te_pool)) / gkf.get_n_splits()\n",
    "\n",
    "print('[CatBoost] OOF RMSPE:', round(rmspe(train[target], cb_oof), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50068b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:32:57.839129Z",
     "iopub.status.busy": "2025-11-08T14:32:57.838842Z",
     "iopub.status.idle": "2025-11-08T14:32:57.867637Z",
     "shell.execute_reply": "2025-11-08T14:32:57.866736Z"
    },
    "papermill": {
     "duration": 0.036216,
     "end_time": "2025-11-08T14:32:57.868962",
     "exception": false,
     "start_time": "2025-11-08T14:32:57.832746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Blend] best w=0.500 | OOF RMSPE=inf\n",
      "[WARN] test has 2799 rows; trimming to 2790.\n",
      "Saved submission.csv: (2790, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>salary_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>86926.285934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>91372.097738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>93880.579379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70838.435748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>59868.766719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  salary_average\n",
       "0   1    86926.285934\n",
       "1   2    91372.097738\n",
       "2   3    93880.579379\n",
       "3   4    70838.435748\n",
       "4   5    59868.766719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10) Blend and make submission (IDs 1..2790, WITH header)\n",
    "\n",
    "# --- pick best blend weight on OOF (robust) ---\n",
    "best_w, best_score = 0.5, float('inf')\n",
    "y_true = y_true_oof if 'y_true_oof' in globals() else train[target].values[:min(len(lgb_oof), len(cb_oof))]\n",
    "for w in np.linspace(0.2, 0.8, 13):\n",
    "    oof = w*np.asarray(lgb_oof, float) + (1-w)*np.asarray(cb_oof, float)\n",
    "    m = min(len(y_true), len(oof))\n",
    "    s = rmspe(y_true[:m], oof[:m])\n",
    "    if np.isfinite(s) and s < best_score:\n",
    "        best_w, best_score = float(w), float(s)\n",
    "print(f\"[Blend] best w={best_w:.3f} | OOF RMSPE={best_score:.4f}\")\n",
    "\n",
    "# --- blended test predictions ---\n",
    "test_pred = best_w*np.asarray(lgb_test, float) + (1-best_w)*np.asarray(cb_test, float)\n",
    "\n",
    "# --- force evaluator row count = 2790 ---\n",
    "N_EXPECTED = 2790\n",
    "if len(test_pred) > N_EXPECTED:\n",
    "    print(f\"[WARN] test has {len(test_pred)} rows; trimming to {N_EXPECTED}.\")\n",
    "    test_pred = test_pred[:N_EXPECTED]\n",
    "elif len(test_pred) < N_EXPECTED:\n",
    "    raise ValueError(f\"Predictions shorter ({len(test_pred)}) than {N_EXPECTED}.\")\n",
    "\n",
    "# --- IDs 1..2790 and proper header ---\n",
    "ids = np.arange(1, N_EXPECTED + 1, dtype=int)\n",
    "sub = pd.DataFrame({'ID': ids, 'salary_average': test_pred})\n",
    "\n",
    "# hard checks\n",
    "assert sub.shape == (N_EXPECTED, 2)\n",
    "assert list(sub.columns) == ['ID', 'salary_average']\n",
    "\n",
    "# SAVE WITH HEADER\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv:\", sub.shape)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "123c09b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:32:57.880624Z",
     "iopub.status.busy": "2025-11-08T14:32:57.880021Z",
     "iopub.status.idle": "2025-11-08T14:32:57.893660Z",
     "shell.execute_reply": "2025-11-08T14:32:57.892701Z"
    },
    "papermill": {
     "duration": 0.0211,
     "end_time": "2025-11-08T14:32:57.895061",
     "exception": false,
     "start_time": "2025-11-08T14:32:57.873961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected test rows: 2799\n",
      "Current test rows used: 2799\n"
     ]
    }
   ],
   "source": [
    "# Re-read pristine test to get the authoritative row count & IDs\n",
    "test_raw = pd.read_csv(f'{DATA_PATH}/test.csv')\n",
    "print('Expected test rows:', len(test_raw))   # should match the error message (e.g., 2790)\n",
    "\n",
    "# What did we submit?\n",
    "print('Current test rows used:', len(test))   # from your current notebook state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcee1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T14:32:57.906535Z",
     "iopub.status.busy": "2025-11-08T14:32:57.906082Z",
     "iopub.status.idle": "2025-11-08T14:32:58.067841Z",
     "shell.execute_reply": "2025-11-08T14:32:58.066695Z"
    },
    "papermill": {
     "duration": 0.169359,
     "end_time": "2025-11-08T14:32:58.069547",
     "exception": false,
     "start_time": "2025-11-08T14:32:57.900188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eee-g513\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14035585,
     "sourceId": 116641,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 204.115932,
   "end_time": "2025-11-08T14:32:59.196832",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-08T14:29:35.080900",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
