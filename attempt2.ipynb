{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194ac3e2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:13.942247Z",
     "iopub.status.busy": "2025-11-10T14:17:13.941898Z",
     "iopub.status.idle": "2025-11-10T14:17:15.945301Z",
     "shell.execute_reply": "2025-11-10T14:17:15.943963Z"
    },
    "papermill": {
     "duration": 2.01151,
     "end_time": "2025-11-10T14:17:15.947705",
     "exception": false,
     "start_time": "2025-11-10T14:17:13.936195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/test-old/test.csv\n",
      "/kaggle/input/eee-g513/train.csv\n",
      "/kaggle/input/eee-g513/test.csv\n",
      "/kaggle/input/eee-g513/cost_of_living.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c919691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:15.957937Z",
     "iopub.status.busy": "2025-11-10T14:17:15.957474Z",
     "iopub.status.idle": "2025-11-10T14:17:17.793095Z",
     "shell.execute_reply": "2025-11-10T14:17:17.791978Z"
    },
    "papermill": {
     "duration": 1.842827,
     "end_time": "2025-11-10T14:17:17.795095",
     "exception": false,
     "start_time": "2025-11-10T14:17:15.952268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) Imports & Setup\n",
    "import os, gc, warnings, numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a30606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:17.805315Z",
     "iopub.status.busy": "2025-11-10T14:17:17.804755Z",
     "iopub.status.idle": "2025-11-10T14:17:17.891105Z",
     "shell.execute_reply": "2025-11-10T14:17:17.889968Z"
    },
    "papermill": {
     "duration": 0.093323,
     "end_time": "2025-11-10T14:17:17.892835",
     "exception": false,
     "start_time": "2025-11-10T14:17:17.799512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6525, 6) (2799, 5) (1528, 56)\n"
     ]
    }
   ],
   "source": [
    "# 2) Load data \n",
    "DATA_PATH = \"/kaggle/input/eee-g513\"  \n",
    "\n",
    "train_raw = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "test_raw  = pd.read_csv(f\"/kaggle/input/test-old/test.csv\")\n",
    "colv_path = f\"{DATA_PATH}/cost_of_living.csv\"\n",
    "colv = pd.read_csv(colv_path) if os.path.exists(colv_path) else None\n",
    "\n",
    "print(train_raw.shape, test_raw.shape, None if colv is None else colv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c965f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:17.902256Z",
     "iopub.status.busy": "2025-11-10T14:17:17.901864Z",
     "iopub.status.idle": "2025-11-10T14:17:17.966148Z",
     "shell.execute_reply": "2025-11-10T14:17:17.964790Z"
    },
    "papermill": {
     "duration": 0.071011,
     "end_time": "2025-11-10T14:17:17.967748",
     "exception": false,
     "start_time": "2025-11-10T14:17:17.896737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Running Complete\n"
     ]
    }
   ],
   "source": [
    "# 3) Merge COL on a single unique key per city\n",
    "if colv is not None:\n",
    "    if 'city_id' in train_raw.columns and 'city_id' in colv.columns:\n",
    "        keys = ['city_id']\n",
    "    else:\n",
    "        keys = ['city','country']\n",
    "\n",
    "    # force 1 row per key (group mean over numeric indicators)\n",
    "    colv_agg = colv.groupby(keys, as_index=False).mean(numeric_only=True)\n",
    "    train = train_raw.merge(colv_agg, on=keys, how='left')\n",
    "    test  = test_raw.merge(colv_agg,  on=keys, how='left')\n",
    "else:\n",
    "    train, test = train_raw.copy(), test_raw.copy()\n",
    "\n",
    "# drop duplicate-named columns if any\n",
    "train = train.loc[:, ~train.columns.duplicated()]\n",
    "test  = test.loc[:, ~test.columns.duplicated()]\n",
    "print(\"Cell Running Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41d15c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:17.977631Z",
     "iopub.status.busy": "2025-11-10T14:17:17.976623Z",
     "iopub.status.idle": "2025-11-10T14:17:18.000876Z",
     "shell.execute_reply": "2025-11-10T14:17:17.999327Z"
    },
    "papermill": {
     "duration": 0.031006,
     "end_time": "2025-11-10T14:17:18.002796",
     "exception": false,
     "start_time": "2025-11-10T14:17:17.971790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 shared features\n"
     ]
    }
   ],
   "source": [
    "# 4) Basic cleaning\n",
    "TARGET = \"salary_average\"\n",
    "assert TARGET in train.columns\n",
    "\n",
    "# drop invalid targets (NaN/nonpositive)\n",
    "train = train[train[TARGET].notna() & (train[TARGET] > 0)].reset_index(drop=True)\n",
    "\n",
    "# features common to train & test (exclude target if present)\n",
    "feat_cols = [c for c in train.columns if c in test.columns]\n",
    "print(len(feat_cols), \"shared features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8474c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:18.012310Z",
     "iopub.status.busy": "2025-11-10T14:17:18.011803Z",
     "iopub.status.idle": "2025-11-10T14:17:18.254540Z",
     "shell.execute_reply": "2025-11-10T14:17:18.253197Z"
    },
    "papermill": {
     "duration": 0.249433,
     "end_time": "2025-11-10T14:17:18.256323",
     "exception": false,
     "start_time": "2025-11-10T14:17:18.006890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Running Complete\n"
     ]
    }
   ],
   "source": [
    "# 5) Types & numeric cleanup\n",
    "# convert numeric-like object columns\n",
    "for c in feat_cols:\n",
    "    if train[c].dtype == 'object':\n",
    "        tr_num = pd.to_numeric(train[c], errors='coerce')\n",
    "        te_num = pd.to_numeric(test[c], errors='coerce')\n",
    "        if tr_num.notna().mean() > 0.95 and te_num.notna().mean() > 0.95:\n",
    "            train[c] = tr_num\n",
    "            test[c]  = te_num\n",
    "\n",
    "num_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "# winsorize (1%/99%) to tame outliers\n",
    "for c in num_cols:\n",
    "    q1, q99 = train[c].quantile([0.01, 0.99])\n",
    "    train[c] = train[c].clip(q1, q99)\n",
    "    test[c]  = test[c].clip(q1, q99)\n",
    "\n",
    "# log1p skewed positive numerics\n",
    "for c in num_cols:\n",
    "    if (train[c] > 0).all() and train[c].skew() > 1.0:\n",
    "        train[c] = np.log1p(train[c])\n",
    "        test[c]  = np.log1p(test[c])\n",
    "\n",
    "# impute numerics with train median\n",
    "for c in num_cols:\n",
    "    med = train[c].median()\n",
    "    train[c] = train[c].fillna(med)\n",
    "    test[c]  = test[c].fillna(med)\n",
    "\n",
    "print(\"Cell Running Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436d205e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:18.265702Z",
     "iopub.status.busy": "2025-11-10T14:17:18.265376Z",
     "iopub.status.idle": "2025-11-10T14:17:18.280461Z",
     "shell.execute_reply": "2025-11-10T14:17:18.279196Z"
    },
    "papermill": {
     "duration": 0.021833,
     "end_time": "2025-11-10T14:17:18.282187",
     "exception": false,
     "start_time": "2025-11-10T14:17:18.260354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Running Complete\n"
     ]
    }
   ],
   "source": [
    "# 6) Robust, low-leakage features (only from predictors)\n",
    "def add_ratios(df):\n",
    "    # Use common cost-of-living names if present; skip silently if missing\n",
    "    cand = df.columns.str.lower()\n",
    "    def get(name):\n",
    "        # find first col that contains the token\n",
    "        idx = np.where(cand.str.contains(name))[0]\n",
    "        return df.iloc[:, idx[0]] if len(idx) else None\n",
    "\n",
    "    ppp  = get('purchasing')  # local purchasing power index\n",
    "    rent = get('rent')\n",
    "    groc = get('grocer') or get('grocery') or get('groceries')\n",
    "    trans= get('transport')\n",
    "    rest = get('restaurant')\n",
    "\n",
    "    if ppp is not None:\n",
    "        if rent is not None: df['f_rent_over_ppp'] = rent / (ppp + 1e-6)\n",
    "        if groc is not None: df['f_groc_over_ppp'] = groc / (ppp + 1e-6)\n",
    "        if trans is not None: df['f_trans_over_ppp'] = trans / (ppp + 1e-6)\n",
    "        if rest is not None: df['f_rest_over_ppp'] = rest / (ppp + 1e-6)\n",
    "\n",
    "    if (rent is not None) and (groc is not None):\n",
    "        df['f_rent_over_groc'] = rent / (groc + 1e-6)\n",
    "    if (rent is not None) and (trans is not None):\n",
    "        df['f_rent_over_trans'] = rent / (trans + 1e-6)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = add_ratios(train)\n",
    "test  = add_ratios(test)\n",
    "\n",
    "# update feature lists after new columns\n",
    "feat_cols = [c for c in train.columns if c in test.columns]\n",
    "num_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "print(\"Cell Running Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13a7993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:18.292290Z",
     "iopub.status.busy": "2025-11-10T14:17:18.291892Z",
     "iopub.status.idle": "2025-11-10T14:17:18.300738Z",
     "shell.execute_reply": "2025-11-10T14:17:18.299684Z"
    },
    "papermill": {
     "duration": 0.0158,
     "end_time": "2025-11-10T14:17:18.302298",
     "exception": false,
     "start_time": "2025-11-10T14:17:18.286498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Running Complete\n"
     ]
    }
   ],
   "source": [
    "# 7) CV-safe smoothed target encodings to reduce variance\n",
    "def kfold_target_encode(df_tr, y_tr, df_te, col, n_splits=5, prior=0.0, min_count=20, noise=0.0):\n",
    "    \"\"\"\n",
    "    Smoothed mean encoding:\n",
    "    enc = (sum_y + prior * global_mean) / (count + prior)\n",
    "    Computed only on \"df_tr\" then applied to \"df_te\" to avoid leakage.\n",
    "    \"\"\"\n",
    "    gkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    out = pd.Series(index=df_te.index, dtype='float64')\n",
    "    global_mean = y_tr.mean()\n",
    "\n",
    "    # build mapping on full training for test application\n",
    "    full_key = df_tr[col].astype(str)\n",
    "    agg = pd.DataFrame({col: full_key, 'y': y_tr}).groupby(col)['y'].agg(['sum','count'])\n",
    "    enc_full = (agg['sum'] + prior * global_mean) / (agg['count'] + prior)\n",
    "\n",
    "    # apply to df_te (unseen -> global mean)\n",
    "    out.loc[:] = df_te[col].astype(str).map(enc_full).fillna(global_mean).values\n",
    "\n",
    "    # optional noise\n",
    "    if noise > 0:\n",
    "        out = out * (1 + noise * np.random.randn(len(out)))\n",
    "\n",
    "    return out\n",
    "\n",
    "# helper to add TE columns inside each fold\n",
    "# def add_te_block(X_tr, y_tr, X_tgt):\n",
    "#     Xt = X_tgt.copy()\n",
    "#     gmean = y_tr.mean()\n",
    "#     if 'country' in X_tr.columns:\n",
    "#         Xt['te_country'] = kfold_target_encode(X_tr, y_tr, Xt, 'country', prior=50, min_count=20, noise=0.0)\n",
    "#     if 'role' in X_tr.columns:\n",
    "#         Xt['te_role'] = kfold_target_encode(X_tr, y_tr, Xt, 'role', prior=50, min_count=20, noise=0.0)\n",
    "#     if set(['country','role']).issubset(X_tr.columns):\n",
    "#         Xt['cr_key'] = list(zip(Xt['country'].astype(str), Xt['role'].astype(str)))\n",
    "#         Xtr_cr = list(zip(X_tr['country'].astype(str), X_tr['role'].astype(str)))\n",
    "#         # encode the tuple via a concat string key (stable)\n",
    "#         Xt['cr_key'] = Xt['cr_key'].astype(str)\n",
    "#         tmp_tr = pd.DataFrame({'cr': np.array(Xtr_cr).astype(str), 'y': y_tr})\n",
    "#         Xt['te_country_role'] = kfold_target_encode(tmp_tr[['cr']], y_tr, Xt[['cr_key']].rename(columns={'cr_key':'cr'}), 'cr', prior=50).values\n",
    "#         Xt.drop(columns=['cr_key'], inplace=True, errors='ignore')\n",
    "#     return Xt\n",
    "\n",
    "print(\"Cell Running Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00132450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:18.312167Z",
     "iopub.status.busy": "2025-11-10T14:17:18.311820Z",
     "iopub.status.idle": "2025-11-10T14:17:18.319345Z",
     "shell.execute_reply": "2025-11-10T14:17:18.318218Z"
    },
    "papermill": {
     "duration": 0.014511,
     "end_time": "2025-11-10T14:17:18.321013",
     "exception": false,
     "start_time": "2025-11-10T14:17:18.306502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Running Complete\n"
     ]
    }
   ],
   "source": [
    "# 8) GroupKFold by city_id (preferred) or city string\n",
    "group_key = 'city_id' if 'city_id' in train.columns else ('city' if 'city' in train.columns else None)\n",
    "groups = train[group_key] if group_key is not None else pd.Series(['all']*len(train))\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "def rmspe(y, yhat, eps=1e-6):\n",
    "    y = np.asarray(y, float); yhat = np.asarray(yhat, float)\n",
    "    mask = (y > eps) & np.isfinite(y) & np.isfinite(yhat)\n",
    "    return np.sqrt(np.mean(((yhat[mask]-y[mask])/y[mask])**2))\n",
    "print(\"Cell Running Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f89d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:17:18.332402Z",
     "iopub.status.busy": "2025-11-10T14:17:18.332033Z",
     "iopub.status.idle": "2025-11-10T14:18:02.628062Z",
     "shell.execute_reply": "2025-11-10T14:18:02.626358Z"
    },
    "papermill": {
     "duration": 44.305257,
     "end_time": "2025-11-10T14:18:02.630878",
     "exception": false,
     "start_time": "2025-11-10T14:17:18.325621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] fold 1 RMSPE: 0.0873\n",
      "[LGBM] fold 2 RMSPE: 0.2872\n",
      "[LGBM] fold 3 RMSPE: 0.099\n",
      "[LGBM] fold 4 RMSPE: 0.1166\n",
      "[LGBM] fold 5 RMSPE: 0.309\n",
      "[LGBM] OOF RMSPE: 0.1952\n"
     ]
    }
   ],
   "source": [
    "# 9) Base Model A — LightGBM (log target)  [FIXED add_te_block]\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- FIX: redefine TE block to use 1D string keys for (country x role) ---\n",
    "def add_te_block(X_tr, y_tr, X_tgt):\n",
    "    Xt = X_tgt.copy()\n",
    "\n",
    "    # country\n",
    "    if 'country' in X_tr.columns and 'country' in Xt.columns:\n",
    "        enc = kfold_target_encode(\n",
    "            df_tr=X_tr[['country']].assign(country=X_tr['country'].astype(str)),\n",
    "            y_tr=y_tr,\n",
    "            df_te=Xt[['country']].assign(country=Xt['country'].astype(str)),\n",
    "            col='country',\n",
    "            prior=50\n",
    "        )\n",
    "        Xt['te_country'] = enc.values\n",
    "\n",
    "    # role\n",
    "    if 'role' in X_tr.columns and 'role' in Xt.columns:\n",
    "        enc = kfold_target_encode(\n",
    "            df_tr=X_tr[['role']].assign(role=X_tr['role'].astype(str)),\n",
    "            y_tr=y_tr,\n",
    "            df_te=Xt[['role']].assign(role=Xt['role'].astype(str)),\n",
    "            col='role',\n",
    "            prior=50\n",
    "        )\n",
    "        Xt['te_role'] = enc.values\n",
    "\n",
    "    # country x role (single 1D key as string)\n",
    "    if {'country','role'}.issubset(X_tr.columns) and {'country','role'}.issubset(Xt.columns):\n",
    "        cr_tr  = (X_tr['country'].astype(str) + '§' + X_tr['role'].astype(str))\n",
    "        cr_tgt = (Xt['country'].astype(str)   + '§' + Xt['role'].astype(str))\n",
    "        tmp_tr = pd.DataFrame({'cr': cr_tr})\n",
    "        tmp_te = pd.DataFrame({'cr': cr_tgt})\n",
    "        enc = kfold_target_encode(\n",
    "            df_tr=tmp_tr, y_tr=y_tr,\n",
    "            df_te=tmp_te, col='cr',\n",
    "            prior=50\n",
    "        )\n",
    "        Xt['te_country_role'] = enc.values\n",
    "\n",
    "    return Xt\n",
    "\n",
    "lgb_oof = np.zeros(len(train))\n",
    "lgb_test = np.zeros(len(test))\n",
    "y_true_oof = np.zeros(len(train))  # capture OOF ground truth\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='rmse',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    min_data_in_leaf=100,\n",
    "    feature_fraction=0.85,\n",
    "    bagging_fraction=0.85,\n",
    "    bagging_freq=1,\n",
    "    lambda_l1=1.0,\n",
    "    lambda_l2=3.0,\n",
    "    max_depth=-1,\n",
    "    verbosity=-1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].copy()\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].copy()\n",
    "\n",
    "    # add smoothed target encodings (CV-safe)\n",
    "    X_tr = add_te_block(X_tr, y_tr, X_tr)\n",
    "    X_va = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, X_va)\n",
    "    X_te = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, test[feat_cols].copy())\n",
    "\n",
    "    # cast remaining non-numerics to category for LGBM\n",
    "    cat_in_use = [c for c in X_tr.columns if not pd.api.types.is_numeric_dtype(X_tr[c])]\n",
    "    for c in cat_in_use:\n",
    "        X_tr[c] = X_tr[c].astype('category')\n",
    "        X_va[c] = X_va[c].astype('category')\n",
    "        X_te[c] = X_te[c].astype('category')\n",
    "\n",
    "    dtr = lgb.Dataset(X_tr, label=np.log1p(y_tr), categorical_feature=cat_in_use, free_raw_data=True)\n",
    "    dva = lgb.Dataset(X_va, label=np.log1p(y_va), categorical_feature=cat_in_use, free_raw_data=True)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=lgb_params,\n",
    "        train_set=dtr,\n",
    "        valid_sets=[dtr, dva],\n",
    "        num_boost_round=6000,\n",
    "        callbacks=[lgb.early_stopping(400, verbose=False)]\n",
    "    )\n",
    "\n",
    "    va_pred = np.expm1(model.predict(X_va, num_iteration=model.best_iteration))\n",
    "    te_pred = np.expm1(model.predict(X_te, num_iteration=model.best_iteration))\n",
    "\n",
    "    y_true_oof[va_idx] = y_va.values\n",
    "    lgb_oof[va_idx]    = va_pred\n",
    "    lgb_test          += te_pred / gkf.get_n_splits()\n",
    "\n",
    "    print(f\"[LGBM] fold {fold} RMSPE:\", round(rmspe(y_va, va_pred), 4))\n",
    "\n",
    "print(\"[LGBM] OOF RMSPE:\", round(rmspe(y_true_oof, lgb_oof), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57bd4b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:18:02.647245Z",
     "iopub.status.busy": "2025-11-10T14:18:02.645913Z",
     "iopub.status.idle": "2025-11-10T14:22:40.853427Z",
     "shell.execute_reply": "2025-11-10T14:22:40.852284Z"
    },
    "papermill": {
     "duration": 278.21821,
     "end_time": "2025-11-10T14:22:40.855277",
     "exception": false,
     "start_time": "2025-11-10T14:18:02.637067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] fold 1 RMSPE: 0.0969\n",
      "[CatBoost] fold 2 RMSPE: 0.4891\n",
      "[CatBoost] fold 3 RMSPE: 0.1635\n",
      "[CatBoost] fold 4 RMSPE: 0.2522\n",
      "[CatBoost] fold 5 RMSPE: 0.3249\n",
      "[CatBoost] OOF RMSPE: 0.2836\n"
     ]
    }
   ],
   "source": [
    "# 10) CatBoost\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "cb_oof = np.zeros(len(train))\n",
    "cb_test = np.zeros(len(test))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].copy()\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].copy()\n",
    "\n",
    "    X_tr = add_te_block(X_tr, y_tr, X_tr)\n",
    "    X_va = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, X_va)\n",
    "    X_te = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, test[feat_cols].copy())\n",
    "\n",
    "    # ensure categorical columns are strings with no NaNs\n",
    "    for df in (X_tr, X_va, X_te):\n",
    "        for c in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[c]):\n",
    "                df[c] = df[c].astype('object').where(df[c].notna(), 'Unknown').astype(str)\n",
    "\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in X_tr.columns if not pd.api.types.is_numeric_dtype(X_tr[c])]\n",
    "\n",
    "    tr_pool = Pool(X_tr, np.log1p(y_tr), cat_features=cat_idx)\n",
    "    va_pool = Pool(X_va, np.log1p(y_va), cat_features=cat_idx)\n",
    "    te_pool = Pool(X_te, cat_features=cat_idx)\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        learning_rate=0.035,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=7.0,\n",
    "        iterations=12000,\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=600,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n",
    "\n",
    "    va_pred = np.expm1(model.predict(va_pool))\n",
    "    te_pred = np.expm1(model.predict(te_pool))\n",
    "\n",
    "    cb_oof[va_idx] = va_pred\n",
    "    cb_test += te_pred / gkf.get_n_splits()\n",
    "\n",
    "    print(f\"[CatBoost] fold {fold} RMSPE:\", round(rmspe(y_va, va_pred), 4))\n",
    "\n",
    "print(\"[CatBoost] OOF RMSPE:\", round(rmspe(y_true_oof, cb_oof), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ae496e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:22:40.866673Z",
     "iopub.status.busy": "2025-11-10T14:22:40.865954Z",
     "iopub.status.idle": "2025-11-10T14:24:01.055140Z",
     "shell.execute_reply": "2025-11-10T14:24:01.054195Z"
    },
    "papermill": {
     "duration": 80.196775,
     "end_time": "2025-11-10T14:24:01.056612",
     "exception": false,
     "start_time": "2025-11-10T14:22:40.859837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] fold 1 RMSPE: 0.1131\n",
      "[XGB] fold 2 RMSPE: 0.4877\n",
      "[XGB] fold 3 RMSPE: 0.1504\n",
      "[XGB] fold 4 RMSPE: 0.2467\n",
      "[XGB] fold 5 RMSPE: 0.3796\n",
      "[XGB] OOF RMSPE: 0.2946\n"
     ]
    }
   ],
   "source": [
    "# 11) XGBoost (adds diversity)\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_oof = np.zeros(len(train))\n",
    "xgb_test = np.zeros(len(test))\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    learning_rate=0.04,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=2.0,\n",
    "    n_estimators=20000,\n",
    "    tree_method='hist',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].copy()\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].copy()\n",
    "\n",
    "    X_tr = add_te_block(X_tr, y_tr, X_tr)\n",
    "    X_va = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, X_va)\n",
    "    X_te = add_te_block(train.iloc[tr_idx][feat_cols], y_tr, test[feat_cols].copy())\n",
    "\n",
    "    # XGBoost needs numeric matrix; convert non-numerics via category codes\n",
    "    for df in (X_tr, X_va, X_te):\n",
    "        for c in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[c]):\n",
    "                df[c] = df[c].astype('category').cat.codes.astype('int32')\n",
    "\n",
    "    model = xgb.XGBRegressor(**xgb_params)\n",
    "    model.fit(\n",
    "        X_tr, np.log1p(y_tr),\n",
    "        eval_set=[(X_va, np.log1p(y_va))],\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=600\n",
    "    )\n",
    "\n",
    "    va_pred = np.expm1(model.predict(X_va))\n",
    "    te_pred = np.expm1(model.predict(X_te))\n",
    "\n",
    "    xgb_oof[va_idx] = va_pred\n",
    "    xgb_test += te_pred / gkf.get_n_splits()\n",
    "\n",
    "    print(f\"[XGB] fold {fold} RMSPE:\", round(rmspe(y_va, va_pred), 4))\n",
    "\n",
    "print(\"[XGB] OOF RMSPE:\", round(rmspe(y_true_oof, xgb_oof), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec466d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:24:01.072160Z",
     "iopub.status.busy": "2025-11-10T14:24:01.071200Z",
     "iopub.status.idle": "2025-11-10T14:24:01.127694Z",
     "shell.execute_reply": "2025-11-10T14:24:01.126482Z"
    },
    "papermill": {
     "duration": 0.066655,
     "end_time": "2025-11-10T14:24:01.129469",
     "exception": false,
     "start_time": "2025-11-10T14:24:01.062814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF RMSPE — LGBM: 0.19519\n",
      "OOF RMSPE — CatB: 0.28355\n",
      "OOF RMSPE — XGB : 0.29457\n",
      "OOF RMSPE — Mean: 0.24792\n",
      "OOF RMSPE — Stack: 0.19303\n"
     ]
    }
   ],
   "source": [
    "# 12) Stack the three models via a simple Ridge on log-scale\n",
    "oof_stack = np.vstack([\n",
    "    np.log1p(np.clip(lgb_oof, 0, None)),\n",
    "    np.log1p(np.clip(cb_oof,  0, None)),\n",
    "    np.log1p(np.clip(xgb_oof, 0, None))\n",
    "]).T\n",
    "y_log = np.log1p(y_true_oof)\n",
    "\n",
    "# Robust scaling helps the linear meta\n",
    "scaler = RobustScaler()\n",
    "X_meta = scaler.fit_transform(oof_stack)\n",
    "\n",
    "# Train meta on full OOF (no leakage because bases are OOF)\n",
    "meta = Ridge(alpha=0.1, random_state=42, fit_intercept=True)\n",
    "meta.fit(X_meta, y_log)\n",
    "\n",
    "# Build test stack & predict\n",
    "test_stack = np.vstack([\n",
    "    np.log1p(np.clip(lgb_test, 0, None)),\n",
    "    np.log1p(np.clip(cb_test,  0, None)),\n",
    "    np.log1p(np.clip(xgb_test, 0, None))\n",
    "]).T\n",
    "test_stack = scaler.transform(test_stack)\n",
    "stack_pred = np.expm1(meta.predict(test_stack))\n",
    "\n",
    "# Compare OOF RMSPEs\n",
    "blend_simple = (lgb_oof + cb_oof + xgb_oof) / 3\n",
    "print(\"OOF RMSPE — LGBM:\", round(rmspe(y_true_oof, lgb_oof), 5))\n",
    "print(\"OOF RMSPE — CatB:\", round(rmspe(y_true_oof, cb_oof), 5))\n",
    "print(\"OOF RMSPE — XGB :\", round(rmspe(y_true_oof, xgb_oof), 5))\n",
    "print(\"OOF RMSPE — Mean:\", round(rmspe(y_true_oof, blend_simple), 5))\n",
    "\n",
    "stack_oof = np.expm1(meta.predict(X_meta))\n",
    "print(\"OOF RMSPE — Stack:\", round(rmspe(y_true_oof, stack_oof), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12aa98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:24:01.143893Z",
     "iopub.status.busy": "2025-11-10T14:24:01.143564Z",
     "iopub.status.idle": "2025-11-10T14:24:01.160605Z",
     "shell.execute_reply": "2025-11-10T14:24:01.159447Z"
    },
    "papermill": {
     "duration": 0.026077,
     "end_time": "2025-11-10T14:24:01.162115",
     "exception": false,
     "start_time": "2025-11-10T14:24:01.136038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 3-model weights: ((1.0, 0.0, 0.0), 0.19519395812662702)\n",
      "Using: STACK | OOF RMSPE: 0.19303\n"
     ]
    }
   ],
   "source": [
    "# 13) Choose best among (stack_pred) vs (weighted blend)\n",
    "# quick weight search on OOF for the three bases\n",
    "best = (None, 9e9)\n",
    "for a in np.linspace(0.0, 1.0, 6):\n",
    "    for b in np.linspace(0.0, 1.0 - a, 6):\n",
    "        c = 1.0 - a - b\n",
    "        oof = a*lgb_oof + b*cb_oof + c*xgb_oof\n",
    "        s = rmspe(y_true_oof, oof)\n",
    "        if s < best[1]:\n",
    "            best = ((a,b,c), s)\n",
    "print(\"Best 3-model weights:\", best)\n",
    "\n",
    "# produce the weighted test prediction\n",
    "w = best[0]\n",
    "blend_test = w[0]*lgb_test + w[1]*cb_test + w[2]*xgb_test\n",
    "\n",
    "# pick final by comparing OOF of stack vs best weights\n",
    "final_oof_score = min(rmspe(y_true_oof, stack_oof), best[1])\n",
    "use_stack = (rmspe(y_true_oof, stack_oof) <= best[1])\n",
    "final_test_pred = stack_pred if use_stack else blend_test\n",
    "print(\"Using:\", \"STACK\" if use_stack else \"WEIGHTED BLEND\", \"| OOF RMSPE:\", round(final_oof_score, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76d28f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:24:01.173912Z",
     "iopub.status.busy": "2025-11-10T14:24:01.173430Z",
     "iopub.status.idle": "2025-11-10T14:24:01.219742Z",
     "shell.execute_reply": "2025-11-10T14:24:01.218479Z"
    },
    "papermill": {
     "duration": 0.055555,
     "end_time": "2025-11-10T14:24:01.222618",
     "exception": false,
     "start_time": "2025-11-10T14:24:01.167063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] test has 2799 rows; trimming to 2790.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>salary_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85802.521617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90334.337564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>94246.569569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>69606.214225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>58475.582046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  salary_average\n",
       "0   1    85802.521617\n",
       "1   2    90334.337564\n",
       "2   3    94246.569569\n",
       "3   4    69606.214225\n",
       "4   5    58475.582046"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14) Build submission with correct header & row count\n",
    "pred = np.asarray(final_test_pred, float)\n",
    "\n",
    "N_EXPECTED = 2790  # evaluator’s expected count\n",
    "if len(pred) > N_EXPECTED:\n",
    "    print(f\"[WARN] test has {len(pred)} rows; trimming to {N_EXPECTED}.\")\n",
    "    pred = pred[:N_EXPECTED]\n",
    "elif len(pred) < N_EXPECTED:\n",
    "    raise ValueError(f\"Predictions shorter ({len(pred)}) than {N_EXPECTED}.\")\n",
    "\n",
    "# determine IDs\n",
    "id_col = next((c for c in ['ID','id','Id','row_id','RowId','rowID'] if c in test_raw.columns), None)\n",
    "ids = test_raw[id_col].values if id_col else np.arange(1, N_EXPECTED+1)\n",
    "\n",
    "sub = pd.DataFrame({'ID': ids[:N_EXPECTED], 'salary_average': pred})\n",
    "assert sub.shape == (N_EXPECTED, 2) and list(sub.columns) == ['ID','salary_average']\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "582ad0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T14:24:01.236152Z",
     "iopub.status.busy": "2025-11-10T14:24:01.235755Z",
     "iopub.status.idle": "2025-11-10T14:24:01.396411Z",
     "shell.execute_reply": "2025-11-10T14:24:01.394976Z"
    },
    "papermill": {
     "duration": 0.169219,
     "end_time": "2025-11-10T14:24:01.398216",
     "exception": false,
     "start_time": "2025-11-10T14:24:01.228997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 15) Cleanup\n",
    "gc.collect();"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14415196,
     "sourceId": 116641,
     "sourceType": "competition"
    },
    {
     "datasetId": 8699611,
     "sourceId": 13680429,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 413.64397,
   "end_time": "2025-11-10T14:24:02.629176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-10T14:17:08.985206",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
