{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2324d3eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:30.849188Z",
     "iopub.status.busy": "2025-11-11T07:00:30.848869Z",
     "iopub.status.idle": "2025-11-11T07:00:42.350873Z",
     "shell.execute_reply": "2025-11-11T07:00:42.349618Z"
    },
    "papermill": {
     "duration": 11.509801,
     "end_time": "2025-11-11T07:00:42.352646",
     "exception": false,
     "start_time": "2025-11-11T07:00:30.842845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/eee-g513/train.csv\n",
      "/kaggle/input/eee-g513/test.csv\n",
      "/kaggle/input/eee-g513/cost_of_living.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# List input files\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:10]:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0483ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.362749Z",
     "iopub.status.busy": "2025-11-11T07:00:42.362053Z",
     "iopub.status.idle": "2025-11-11T07:00:42.455685Z",
     "shell.execute_reply": "2025-11-11T07:00:42.454393Z"
    },
    "papermill": {
     "duration": 0.100402,
     "end_time": "2025-11-11T07:00:42.457513",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.357111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (6525, 6), Test: (2790, 5), COL: (1528, 56)\n",
      "\n",
      "Target stats:\n",
      "count      6480.000000\n",
      "mean      53169.866584\n",
      "std       27592.877914\n",
      "min        3836.556547\n",
      "25%       28697.390996\n",
      "50%       54673.064063\n",
      "75%       72742.000000\n",
      "max      157747.634644\n",
      "Name: salary_average, dtype: float64\n",
      "\n",
      "Missing in train:\n",
      "salary_average    45\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data with Proper Handling\n",
    "DATA_PATH = \"/kaggle/input/eee-g513\"\n",
    "\n",
    "train_raw = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "test_raw = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
    "colv_path = f\"{DATA_PATH}/cost_of_living.csv\"\n",
    "colv = pd.read_csv(colv_path) if os.path.exists(colv_path) else None\n",
    "\n",
    "print(f\"Train: {train_raw.shape}, Test: {test_raw.shape}, COL: {colv.shape if colv is not None else None}\")\n",
    "print(f\"\\nTarget stats:\\n{train_raw['salary_average'].describe()}\")\n",
    "print(f\"\\nMissing in train:\\n{train_raw.isnull().sum()[train_raw.isnull().sum() > 0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2d9847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.468264Z",
     "iopub.status.busy": "2025-11-11T07:00:42.467430Z",
     "iopub.status.idle": "2025-11-11T07:00:42.516242Z",
     "shell.execute_reply": "2025-11-11T07:00:42.515082Z"
    },
    "papermill": {
     "duration": 0.056514,
     "end_time": "2025-11-11T07:00:42.518101",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.461587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge - Train: (6525, 59), Test: (2790, 58)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Smart COL Merge - Use Median Aggregation Per City\n",
    "if colv is not None:\n",
    "    # Identify merge keys\n",
    "    if 'city_id' in train_raw.columns and 'city_id' in colv.columns:\n",
    "        keys = ['city_id']\n",
    "    else:\n",
    "        keys = ['city', 'country']\n",
    "    \n",
    "    # Aggregate COL with median (more robust than mean)\n",
    "    colv_agg = colv.groupby(keys, as_index=False).median(numeric_only=True)\n",
    "    \n",
    "    train = train_raw.merge(colv_agg, on=keys, how='left', suffixes=('', '_drop'))\n",
    "    test = test_raw.merge(colv_agg, on=keys, how='left', suffixes=('', '_drop'))\n",
    "    \n",
    "    # Drop duplicate columns\n",
    "    train = train[[c for c in train.columns if not c.endswith('_drop')]]\n",
    "    test = test[[c for c in test.columns if not c.endswith('_drop')]]\n",
    "else:\n",
    "    train, test = train_raw.copy(), test_raw.copy()\n",
    "\n",
    "print(f\"After merge - Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548dd086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.527959Z",
     "iopub.status.busy": "2025-11-11T07:00:42.527631Z",
     "iopub.status.idle": "2025-11-11T07:00:42.546202Z",
     "shell.execute_reply": "2025-11-11T07:00:42.544969Z"
    },
    "papermill": {
     "duration": 0.025382,
     "end_time": "2025-11-11T07:00:42.547793",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.522411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 45 invalid targets\n",
      "Features: 58\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Target Cleaning and Feature Selection\n",
    "TARGET = \"salary_average\"\n",
    "\n",
    "# Remove invalid targets\n",
    "before = len(train)\n",
    "train = train[train[TARGET].notna() & (train[TARGET] > 0)].reset_index(drop=True)\n",
    "print(f\"Dropped {before - len(train)} invalid targets\")\n",
    "\n",
    "# Identify common features (exclude target)\n",
    "feat_cols = [c for c in train.columns if c in test.columns and c != TARGET]\n",
    "print(f\"Features: {len(feat_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c9b1da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.557946Z",
     "iopub.status.busy": "2025-11-11T07:00:42.557332Z",
     "iopub.status.idle": "2025-11-11T07:00:42.571358Z",
     "shell.execute_reply": "2025-11-11T07:00:42.570305Z"
    },
    "papermill": {
     "duration": 0.020902,
     "end_time": "2025-11-11T07:00:42.573056",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.552154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Advanced Feature Engineering\n",
    "def create_interaction_features(df):\n",
    "    \"\"\"Create domain-informed interaction features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Find COL columns by partial name matching (case-insensitive)\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    def find_col(keywords):\n",
    "        for kw in keywords:\n",
    "            for lower, actual in cols_lower.items():\n",
    "                if kw in lower:\n",
    "                    return actual\n",
    "        return None\n",
    "    \n",
    "    # Key COL indicators\n",
    "    ppp = find_col(['purchasing', 'power'])\n",
    "    rent = find_col(['rent'])\n",
    "    groc = find_col(['grocer'])\n",
    "    rest = find_col(['restaurant'])\n",
    "    trans = find_col(['transport'])\n",
    "    local = find_col(['local_purchasing'])\n",
    "    \n",
    "    # Purchasing power ratios (critical for salary normalization)\n",
    "    if ppp is not None and pd.api.types.is_numeric_dtype(df[ppp]):\n",
    "        if rent is not None and pd.api.types.is_numeric_dtype(df[rent]):\n",
    "            df['affordability_rent'] = df[rent] / (df[ppp] + 1)\n",
    "        if groc is not None and pd.api.types.is_numeric_dtype(df[groc]):\n",
    "            df['affordability_food'] = df[groc] / (df[ppp] + 1)\n",
    "        if trans is not None and pd.api.types.is_numeric_dtype(df[trans]):\n",
    "            df['affordability_trans'] = df[trans] / (df[ppp] + 1)\n",
    "    \n",
    "    # Cost burden ratios\n",
    "    if rent is not None and groc is not None:\n",
    "        if pd.api.types.is_numeric_dtype(df[rent]) and pd.api.types.is_numeric_dtype(df[groc]):\n",
    "            df['housing_to_food'] = df[rent] / (df[groc] + 1)\n",
    "    \n",
    "    # Composite cost of living index\n",
    "    cost_cols = []\n",
    "    for col_name in [rent, groc, rest, trans]:\n",
    "        if col_name and pd.api.types.is_numeric_dtype(df[col_name]):\n",
    "            cost_cols.append(col_name)\n",
    "    \n",
    "    if len(cost_cols) >= 2:\n",
    "        df['composite_col_index'] = df[cost_cols].mean(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = create_interaction_features(train)\n",
    "test = create_interaction_features(test)\n",
    "\n",
    "# Update feature list\n",
    "feat_cols = [c for c in train.columns if c in test.columns and c != TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e7cb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.582329Z",
     "iopub.status.busy": "2025-11-11T07:00:42.582026Z",
     "iopub.status.idle": "2025-11-11T07:00:42.831514Z",
     "shell.execute_reply": "2025-11-11T07:00:42.830297Z"
    },
    "papermill": {
     "duration": 0.256263,
     "end_time": "2025-11-11T07:00:42.833302",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.577039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: 54, Categorical: 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Type Detection and Numeric Preprocessing\n",
    "# Convert numeric-like objects\n",
    "for c in feat_cols:\n",
    "    if train[c].dtype == 'object':\n",
    "        tr_num = pd.to_numeric(train[c], errors='coerce')\n",
    "        te_num = pd.to_numeric(test[c], errors='coerce')\n",
    "        if tr_num.notna().mean() > 0.9:  # Stricter threshold\n",
    "            train[c] = tr_num\n",
    "            test[c] = te_num\n",
    "\n",
    "# Separate numeric and categorical\n",
    "num_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in feat_cols if c not in num_cols]\n",
    "\n",
    "print(f\"Numeric: {len(num_cols)}, Categorical: {len(cat_cols)}\")\n",
    "\n",
    "# Robust outlier handling (winsorize at 0.5% and 99.5%)\n",
    "for c in num_cols:\n",
    "    q_low, q_high = train[c].quantile([0.005, 0.995])\n",
    "    train[c] = train[c].clip(q_low, q_high)\n",
    "    test[c] = test[c].clip(q_low, q_high)\n",
    "\n",
    "# Log-transform heavily skewed features\n",
    "for c in num_cols:\n",
    "    if (train[c] > 0).all() and train[c].skew() > 2.0:  # Higher threshold\n",
    "        train[c] = np.log1p(train[c])\n",
    "        test[c] = np.log1p(test[c])\n",
    "\n",
    "# Impute with median\n",
    "for c in num_cols:\n",
    "    med = train[c].median()\n",
    "    train[c] = train[c].fillna(med)\n",
    "    test[c] = test[c].fillna(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83786983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.842892Z",
     "iopub.status.busy": "2025-11-11T07:00:42.842542Z",
     "iopub.status.idle": "2025-11-11T07:00:42.852775Z",
     "shell.execute_reply": "2025-11-11T07:00:42.851451Z"
    },
    "papermill": {
     "duration": 0.017198,
     "end_time": "2025-11-11T07:00:42.854538",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.837340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 7: Smoothed Target Encoding (CV-Safe)\n",
    "def smoothed_target_encode(train_df, y_train, test_df, col, alpha=50):\n",
    "    \"\"\"\n",
    "    Bayesian smoothed mean encoding with proper CV to prevent leakage\n",
    "    \"\"\"\n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    # Compute smoothed means on training data\n",
    "    stats = pd.DataFrame({\n",
    "        'key': train_df[col].astype(str),\n",
    "        'target': y_train\n",
    "    }).groupby('key').agg(\n",
    "        sum_y=('target', 'sum'),\n",
    "        count=('target', 'count')\n",
    "    )\n",
    "    \n",
    "    # Smoothing: (sum_y + alpha * global_mean) / (count + alpha)\n",
    "    stats['encoded'] = (stats['sum_y'] + alpha * global_mean) / (stats['count'] + alpha)\n",
    "    \n",
    "    # Map to test data\n",
    "    encoded = test_df[col].astype(str).map(stats['encoded']).fillna(global_mean)\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "def add_target_encodings(X_train, y_train, X_target):\n",
    "    \"\"\"Add all target encodings\"\"\"\n",
    "    X_out = X_target.copy()\n",
    "    \n",
    "    if 'country' in X_train.columns:\n",
    "        X_out['te_country'] = smoothed_target_encode(X_train, y_train, X_out, 'country', alpha=100)\n",
    "    \n",
    "    if 'role' in X_train.columns:\n",
    "        X_out['te_role'] = smoothed_target_encode(X_train, y_train, X_out, 'role', alpha=50)\n",
    "    \n",
    "    if 'state' in X_train.columns:\n",
    "        X_out['te_state'] = smoothed_target_encode(X_train, y_train, X_out, 'state', alpha=30)\n",
    "    \n",
    "    # Interaction: country x role\n",
    "    if {'country', 'role'}.issubset(X_train.columns):\n",
    "        X_train_temp = X_train.copy()\n",
    "        X_out_temp = X_out.copy()\n",
    "        X_train_temp['country_role'] = X_train['country'].astype(str) + '_' + X_train['role'].astype(str)\n",
    "        X_out_temp['country_role'] = X_out['country'].astype(str) + '_' + X_out['role'].astype(str)\n",
    "        X_out['te_country_role'] = smoothed_target_encode(X_train_temp, y_train, X_out_temp, 'country_role', alpha=200)\n",
    "    \n",
    "    return X_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765b1ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.863938Z",
     "iopub.status.busy": "2025-11-11T07:00:42.863628Z",
     "iopub.status.idle": "2025-11-11T07:00:42.872732Z",
     "shell.execute_reply": "2025-11-11T07:00:42.871283Z"
    },
    "papermill": {
     "duration": 0.015886,
     "end_time": "2025-11-11T07:00:42.874477",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.858591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Strategy: GroupKFold on 'city_id' with 5 folds\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Setup Cross-Validation\n",
    "group_key = 'city_id' if 'city_id' in train.columns else ('city' if 'city' in train.columns else 'country')\n",
    "groups = train[group_key] if group_key else pd.Series(range(len(train)))\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "def rmspe(y_true, y_pred, eps=1e-6):\n",
    "    \"\"\"Root Mean Square Percentage Error\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    mask = (y_true > eps) & np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if mask.sum() == 0:\n",
    "        return np.inf\n",
    "    return np.sqrt(np.mean(((y_true[mask] - y_pred[mask]) / y_true[mask]) ** 2))\n",
    "\n",
    "print(f\"CV Strategy: GroupKFold on '{group_key}' with {gkf.get_n_splits()} folds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a5884c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:42.884869Z",
     "iopub.status.busy": "2025-11-11T07:00:42.883806Z",
     "iopub.status.idle": "2025-11-11T07:00:50.466017Z",
     "shell.execute_reply": "2025-11-11T07:00:50.465033Z"
    },
    "papermill": {
     "duration": 7.588784,
     "end_time": "2025-11-11T07:00:50.467433",
     "exception": false,
     "start_time": "2025-11-11T07:00:42.878649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LightGBM Training ===\n",
      "Fold 1: RMSPE = 0.2513 | Best Iteration = 368\n",
      "Fold 2: RMSPE = 1.2001 | Best Iteration = 880\n",
      "Fold 3: RMSPE = 0.5416 | Best Iteration = 669\n",
      "Fold 4: RMSPE = 0.6738 | Best Iteration = 599\n",
      "Fold 5: RMSPE = 0.5367 | Best Iteration = 594\n",
      "\n",
      "LGBM OOF RMSPE: 0.6787\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: LightGBM with Conservative Hyperparameters\n",
    "lgb_oof = np.zeros(len(train))\n",
    "lgb_test = np.zeros(len(test))\n",
    "y_oof_true = np.zeros(len(train))\n",
    "\n",
    "lgb_params = {\n",
    "    'objective': 'rmse',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.02,  # Lower learning rate\n",
    "    'num_leaves': 24,  # Reduced complexity\n",
    "    'min_data_in_leaf': 150,  # More regularization\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 2.0,  # Increased L1\n",
    "    'lambda_l2': 5.0,  # Increased L2\n",
    "    'max_depth': 6,  # Limit depth\n",
    "    'min_gain_to_split': 0.01,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"\\n=== LightGBM Training ===\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].values\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].values\n",
    "    \n",
    "    # Add target encodings (CV-safe)\n",
    "    X_tr_enc = add_target_encodings(X_tr, y_tr, X_tr)\n",
    "    X_va_enc = add_target_encodings(X_tr, y_tr, X_va)\n",
    "    X_te_enc = add_target_encodings(X_tr, y_tr, test[feat_cols].copy())\n",
    "    \n",
    "    # Categorical handling\n",
    "    cat_features = [c for c in X_tr_enc.columns if not pd.api.types.is_numeric_dtype(X_tr_enc[c])]\n",
    "    for c in cat_features:\n",
    "        X_tr_enc[c] = X_tr_enc[c].astype('category')\n",
    "        X_va_enc[c] = X_va_enc[c].astype('category')\n",
    "        X_te_enc[c] = X_te_enc[c].astype('category')\n",
    "    \n",
    "    # Train on log-scale target\n",
    "    dtrain = lgb.Dataset(X_tr_enc, label=np.log1p(y_tr), categorical_feature=cat_features)\n",
    "    dvalid = lgb.Dataset(X_va_enc, label=np.log1p(y_va), categorical_feature=cat_features)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        dtrain,\n",
    "        valid_sets=[dtrain, dvalid],\n",
    "        num_boost_round=10000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=500, verbose=False),\n",
    "            lgb.log_evaluation(period=0)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    va_pred = np.expm1(model.predict(X_va_enc, num_iteration=model.best_iteration))\n",
    "    te_pred = np.expm1(model.predict(X_te_enc, num_iteration=model.best_iteration))\n",
    "    \n",
    "    lgb_oof[va_idx] = va_pred\n",
    "    lgb_test += te_pred / gkf.n_splits\n",
    "    y_oof_true[va_idx] = y_va\n",
    "    \n",
    "    fold_score = rmspe(y_va, va_pred)\n",
    "    print(f\"Fold {fold}: RMSPE = {fold_score:.4f} | Best Iteration = {model.best_iteration}\")\n",
    "\n",
    "lgb_cv_score = rmspe(y_oof_true, lgb_oof)\n",
    "print(f\"\\nLGBM OOF RMSPE: {lgb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb418d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:00:50.479000Z",
     "iopub.status.busy": "2025-11-11T07:00:50.478672Z",
     "iopub.status.idle": "2025-11-11T07:01:48.335965Z",
     "shell.execute_reply": "2025-11-11T07:01:48.334519Z"
    },
    "papermill": {
     "duration": 57.86555,
     "end_time": "2025-11-11T07:01:48.338176",
     "exception": false,
     "start_time": "2025-11-11T07:00:50.472626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CatBoost Training ===\n",
      "Fold 1: RMSPE = 0.3212 | Best Iteration = 1425\n",
      "Fold 2: RMSPE = 1.2703 | Best Iteration = 786\n",
      "Fold 3: RMSPE = 0.7586 | Best Iteration = 435\n",
      "Fold 4: RMSPE = 0.8701 | Best Iteration = 615\n",
      "Fold 5: RMSPE = 0.6922 | Best Iteration = 487\n",
      "\n",
      "CatBoost OOF RMSPE: 0.8009\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: CatBoost with Conservative Settings\n",
    "cb_oof = np.zeros(len(train))\n",
    "cb_test = np.zeros(len(test))\n",
    "\n",
    "print(\"\\n=== CatBoost Training ===\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].values\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].values\n",
    "    \n",
    "    # Add target encodings\n",
    "    X_tr_enc = add_target_encodings(X_tr, y_tr, X_tr)\n",
    "    X_va_enc = add_target_encodings(X_tr, y_tr, X_va)\n",
    "    X_te_enc = add_target_encodings(X_tr, y_tr, test[feat_cols].copy())\n",
    "    \n",
    "    # Ensure categorical columns are strings\n",
    "    cat_features = []\n",
    "    for i, c in enumerate(X_tr_enc.columns):\n",
    "        if not pd.api.types.is_numeric_dtype(X_tr_enc[c]):\n",
    "            cat_features.append(i)\n",
    "            for df in [X_tr_enc, X_va_enc, X_te_enc]:\n",
    "                df[c] = df[c].astype(str).fillna('Unknown')\n",
    "    \n",
    "    # Create pools\n",
    "    train_pool = Pool(X_tr_enc, np.log1p(y_tr), cat_features=cat_features)\n",
    "    valid_pool = Pool(X_va_enc, np.log1p(y_va), cat_features=cat_features)\n",
    "    test_pool = Pool(X_te_enc, cat_features=cat_features)\n",
    "    \n",
    "    model = CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        learning_rate=0.02,\n",
    "        depth=5,  # Reduced depth\n",
    "        l2_leaf_reg=10.0,  # More regularization\n",
    "        iterations=15000,\n",
    "        early_stopping_rounds=700,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
    "    \n",
    "    va_pred = np.expm1(model.predict(valid_pool))\n",
    "    te_pred = np.expm1(model.predict(test_pool))\n",
    "    \n",
    "    cb_oof[va_idx] = va_pred\n",
    "    cb_test += te_pred / gkf.n_splits\n",
    "    \n",
    "    fold_score = rmspe(y_va, va_pred)\n",
    "    print(f\"Fold {fold}: RMSPE = {fold_score:.4f} | Best Iteration = {model.get_best_iteration()}\")\n",
    "\n",
    "cb_cv_score = rmspe(y_oof_true, cb_oof)\n",
    "print(f\"\\nCatBoost OOF RMSPE: {cb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc00991d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:01:48.349690Z",
     "iopub.status.busy": "2025-11-11T07:01:48.349259Z",
     "iopub.status.idle": "2025-11-11T07:02:37.071214Z",
     "shell.execute_reply": "2025-11-11T07:02:37.069656Z"
    },
    "papermill": {
     "duration": 48.729898,
     "end_time": "2025-11-11T07:02:37.072864",
     "exception": false,
     "start_time": "2025-11-11T07:01:48.342966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Training ===\n",
      "Fold 1: RMSPE = 0.3281\n",
      "Fold 2: RMSPE = 1.3218\n",
      "Fold 3: RMSPE = 0.6852\n",
      "Fold 4: RMSPE = 0.7783\n",
      "Fold 5: RMSPE = 0.6670\n",
      "\n",
      "XGBoost OOF RMSPE: 0.7840\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: XGBoost for Diversity\n",
    "xgb_oof = np.zeros(len(train))\n",
    "xgb_test = np.zeros(len(test))\n",
    "\n",
    "print(\"\\n=== XGBoost Training ===\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
    "    X_tr = train.iloc[tr_idx][feat_cols].copy()\n",
    "    y_tr = train.iloc[tr_idx][TARGET].values\n",
    "    X_va = train.iloc[va_idx][feat_cols].copy()\n",
    "    y_va = train.iloc[va_idx][TARGET].values\n",
    "    \n",
    "    X_tr_enc = add_target_encodings(X_tr, y_tr, X_tr)\n",
    "    X_va_enc = add_target_encodings(X_tr, y_tr, X_va)\n",
    "    X_te_enc = add_target_encodings(X_tr, y_tr, test[feat_cols].copy())\n",
    "    \n",
    "    # Encode categoricals as integers\n",
    "    for c in X_tr_enc.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X_tr_enc[c]):\n",
    "            for df in [X_tr_enc, X_va_enc, X_te_enc]:\n",
    "                df[c] = df[c].astype('category').cat.codes\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        learning_rate=0.02,\n",
    "        max_depth=5,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_alpha=2.0,\n",
    "        reg_lambda=5.0,\n",
    "        n_estimators=15000,\n",
    "        early_stopping_rounds=700,\n",
    "        random_state=42,\n",
    "        tree_method='hist'\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_tr_enc, np.log1p(y_tr),\n",
    "        eval_set=[(X_va_enc, np.log1p(y_va))],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    va_pred = np.expm1(model.predict(X_va_enc))\n",
    "    te_pred = np.expm1(model.predict(X_te_enc))\n",
    "    \n",
    "    xgb_oof[va_idx] = va_pred\n",
    "    xgb_test += te_pred / gkf.n_splits\n",
    "    \n",
    "    fold_score = rmspe(y_va, va_pred)\n",
    "    print(f\"Fold {fold}: RMSPE = {fold_score:.4f}\")\n",
    "\n",
    "xgb_cv_score = rmspe(y_oof_true, xgb_oof)\n",
    "print(f\"\\nXGBoost OOF RMSPE: {xgb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb3aad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:02:37.085328Z",
     "iopub.status.busy": "2025-11-11T07:02:37.084978Z",
     "iopub.status.idle": "2025-11-11T07:02:37.162508Z",
     "shell.execute_reply": "2025-11-11T07:02:37.161450Z"
    },
    "papermill": {
     "duration": 0.086114,
     "end_time": "2025-11-11T07:02:37.164687",
     "exception": false,
     "start_time": "2025-11-11T07:02:37.078573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ensemble Stacking ===\n",
      "\n",
      "=== Cross-Validation Results ===\n",
      "LGBM OOF:        0.6787\n",
      "CatBoost OOF:    0.8009\n",
      "XGBoost OOF:     0.7840\n",
      "Simple Blend:    0.7499\n",
      "Stacked Ridge:   0.5322\n",
      "\n",
      ">>> Selected: Stacked Ridge (OOF RMSPE: 0.5322) <<<\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Ensemble with Ridge Stacking\n",
    "print(\"\\n=== Ensemble Stacking ===\")\n",
    "\n",
    "# Create meta-features (log-scale for stability)\n",
    "oof_meta = np.column_stack([\n",
    "    np.log1p(np.clip(lgb_oof, 0, None)),\n",
    "    np.log1p(np.clip(cb_oof, 0, None)),\n",
    "    np.log1p(np.clip(xgb_oof, 0, None))\n",
    "])\n",
    "\n",
    "test_meta = np.column_stack([\n",
    "    np.log1p(np.clip(lgb_test, 0, None)),\n",
    "    np.log1p(np.clip(cb_test, 0, None)),\n",
    "    np.log1p(np.clip(xgb_test, 0, None))\n",
    "])\n",
    "\n",
    "# Robust scaling\n",
    "scaler = RobustScaler()\n",
    "oof_meta_scaled = scaler.fit_transform(oof_meta)\n",
    "test_meta_scaled = scaler.transform(test_meta)\n",
    "\n",
    "# Train meta-model\n",
    "meta_model = Ridge(alpha=1.0, random_state=42)\n",
    "meta_model.fit(oof_meta_scaled, np.log1p(y_oof_true))\n",
    "\n",
    "# Final predictions\n",
    "stacked_oof = np.expm1(meta_model.predict(oof_meta_scaled))\n",
    "stacked_test = np.expm1(meta_model.predict(test_meta_scaled))\n",
    "\n",
    "# Compare all approaches\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "print(f\"LGBM OOF:        {lgb_cv_score:.4f}\")\n",
    "print(f\"CatBoost OOF:    {cb_cv_score:.4f}\")\n",
    "print(f\"XGBoost OOF:     {xgb_cv_score:.4f}\")\n",
    "\n",
    "simple_blend = (lgb_oof + cb_oof + xgb_oof) / 3\n",
    "blend_score = rmspe(y_oof_true, simple_blend)\n",
    "print(f\"Simple Blend:    {blend_score:.4f}\")\n",
    "\n",
    "stacked_score = rmspe(y_oof_true, stacked_oof)\n",
    "print(f\"Stacked Ridge:   {stacked_score:.4f}\")\n",
    "\n",
    "# Choose best approach\n",
    "if stacked_score < min(lgb_cv_score, cb_cv_score, xgb_cv_score, blend_score):\n",
    "    final_pred = stacked_test\n",
    "    final_method = \"Stacked Ridge\"\n",
    "    final_score = stacked_score\n",
    "elif blend_score < min(lgb_cv_score, cb_cv_score, xgb_cv_score):\n",
    "    final_pred = (lgb_test + cb_test + xgb_test) / 3\n",
    "    final_method = \"Simple Blend\"\n",
    "    final_score = blend_score\n",
    "else:\n",
    "    # Use best single model\n",
    "    best_idx = np.argmin([lgb_cv_score, cb_cv_score, xgb_cv_score])\n",
    "    final_pred = [lgb_test, cb_test, xgb_test][best_idx]\n",
    "    final_method = [\"LGBM\", \"CatBoost\", \"XGBoost\"][best_idx]\n",
    "    final_score = [lgb_cv_score, cb_cv_score, xgb_cv_score][best_idx]\n",
    "\n",
    "print(f\"\\n>>> Selected: {final_method} (OOF RMSPE: {final_score:.4f}) <<<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0747672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:02:37.176771Z",
     "iopub.status.busy": "2025-11-11T07:02:37.176372Z",
     "iopub.status.idle": "2025-11-11T07:02:37.204129Z",
     "shell.execute_reply": "2025-11-11T07:02:37.202718Z"
    },
    "papermill": {
     "duration": 0.035633,
     "end_time": "2025-11-11T07:02:37.205780",
     "exception": false,
     "start_time": "2025-11-11T07:02:37.170147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission shape: (2790, 2)\n",
      "Expected rows: 2790\n",
      "Columns: ['ID', 'salary_average']\n",
      "\n",
      "✓ Submission saved: submission.csv\n",
      "   ID  salary_average\n",
      "0   1    90484.162152\n",
      "1   2    92672.971157\n",
      "2   3    96548.937830\n",
      "3   4    64562.723753\n",
      "4   5    55493.144079\n",
      "5   6    67424.772273\n",
      "6   7    55538.510575\n",
      "7   8    66803.790650\n",
      "8   9    91852.603821\n",
      "9  10    86568.258842\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Create Submission (NO TRIMMING - Use All Test Rows)\n",
    "# Get actual test IDs\n",
    "id_col = next((c for c in ['ID', 'id', 'Id'] if c in test_raw.columns), None)\n",
    "\n",
    "if id_col:\n",
    "    test_ids = test_raw[id_col].values\n",
    "else:\n",
    "    test_ids = np.arange(1, len(test_raw) + 1)\n",
    "\n",
    "# Create submission with ALL test rows\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'salary_average': final_pred\n",
    "})\n",
    "\n",
    "# Validate\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Expected rows: {len(test_raw)}\")\n",
    "print(f\"Columns: {list(submission.columns)}\")\n",
    "assert submission.shape[0] == len(test_raw), \"Row count mismatch!\"\n",
    "assert list(submission.columns) == ['ID', 'salary_average'], \"Column mismatch!\"\n",
    "\n",
    "# Save\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\n✓ Submission saved: submission.csv\")\n",
    "print(submission.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da62bd12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-11T07:02:37.219544Z",
     "iopub.status.busy": "2025-11-11T07:02:37.218398Z",
     "iopub.status.idle": "2025-11-11T07:02:37.347820Z",
     "shell.execute_reply": "2025-11-11T07:02:37.346406Z"
    },
    "papermill": {
     "duration": 0.138674,
     "end_time": "2025-11-11T07:02:37.349694",
     "exception": false,
     "start_time": "2025-11-11T07:02:37.211020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Cleanup\n",
    "gc.collect()\n",
    "print(\"\\n✓ Pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14422847,
     "sourceId": 116641,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 133.212425,
   "end_time": "2025-11-11T07:02:38.276780",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-11T07:00:25.064355",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
